{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Pl7V1UFv6D"
      },
      "source": [
        "#**Capstone Project - Colon Cancer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0RzVVG_GFIp"
      },
      "source": [
        "###DataSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bksv4KInGZoX"
      },
      "source": [
        "Get Kaggle Dataset into GoogleColab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP5ZMUWWGvIm"
      },
      "source": [
        "##**Code - Colon Cancer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEncClbaL_OU"
      },
      "source": [
        "###**AlexNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rw-LxGTYg-n"
      },
      "source": [
        "Import all libraries required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj6UBEOKMDME",
        "outputId": "7d4aad32-0e22-411d-9ff1-af1763561ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.3)\n",
            "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ertifi (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ertifi (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ertifi (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ertifi (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ertifi (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ertifi (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from keras.callbacks import EarlyStopping\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1e4QAYFOG7T",
        "outputId": "08a2fb01-4bba-4182-c28d-ddd2d214d035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7000 images belonging to 2 classes.\n",
            "Found 3000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"colon_image_sets\"\n",
        "SIZE_X = SIZE_Y = 227\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.3)\n",
        "\n",
        "train_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X,SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='training',\n",
        "                                       seed = 42)\n",
        "\n",
        "validate_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X, SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='validation',\n",
        "                                       seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ9AFlH4OJxi"
      },
      "outputs": [],
      "source": [
        "def get_features(base_model, train, validate):\n",
        "    X_train = base_model.predict(train)\n",
        "    y_train = train.classes\n",
        "\n",
        "    X_val = base_model.predict(validate)\n",
        "    y_val = validate.classes\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5, shuffle = True)\n",
        "    print('Shape of X_train----->', str(X_train.shape))\n",
        "    print('Shape of X_val----->', str(X_val.shape))\n",
        "    print('Shape of X_test----->', str(X_test.shape))\n",
        "    return (X_train, X_val, X_test, y_train, y_val, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YggB7bwjOMpM"
      },
      "outputs": [],
      "source": [
        "def get_models():\n",
        "    ANN = Sequential()\n",
        "    ANN.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
        "    ANN.add(BatchNormalization())\n",
        "    ANN.add(Dropout(0.2))\n",
        "    ANN.add(Dense(64, activation='relu'))\n",
        "    ANN.add(Dense(32, activation='relu'))\n",
        "    ANN.add(Dense(16, activation='relu'))\n",
        "    ANN.add(Dense(8, activation='relu'))\n",
        "    ANN.add(Dense(len(train_it.class_indices), activation='softmax'))\n",
        "    ANN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    LR = LogisticRegression()\n",
        "\n",
        "    KNN = KNeighborsClassifier()\n",
        "\n",
        "    SVM = SVC(kernel = 'linear')\n",
        "\n",
        "    RF = RandomForestClassifier(n_estimators = 50)\n",
        "\n",
        "    XGB = XGBClassifier(n_estimators = 50, use_label_encoder=False)\n",
        "\n",
        "    return (ANN, LR, KNN, SVM, RF, XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIaxT7UjORYr"
      },
      "outputs": [],
      "source": [
        "def reshape_data(X_train, X_val, X_test):\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_val = X_val.reshape(X_val.shape[0], -1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    print(\"Shape after reshaping------->\")\n",
        "    print(\"X train------->\", str(X_train.shape))\n",
        "    print(\"X val-------->\", str(X_val.shape))\n",
        "    print(\"X test-------->\", str(X_test.shape))\n",
        "\n",
        "    return (X_train, X_val, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3jAxxAGOT76"
      },
      "outputs": [],
      "source": [
        "def fit_ANN(model, X_train, y_train, X_val, y_test):\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_test), epochs=10, verbose=1, callbacks=[es])\n",
        "    return model\n",
        "\n",
        "def fit_model(model, X_train, y_train):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teXBkhmtOcY2",
        "outputId": "98fbb863-b843-4fa5-8f0b-3d40e78e8afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 55, 55, 96)        34944     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 27, 27, 96)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 27, 27, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 13, 13, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 13, 13, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 13, 13, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 13, 13, 256)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4096)              37752832  \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,378,344\n",
            "Trainable params: 62,378,344\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "\n",
        "def create_alexnet(input_shape):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # First Convolutional Layer\n",
        "    x = Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu')(input_layer)\n",
        "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n",
        "\n",
        "    # Second Convolutional Layer\n",
        "    x = Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n",
        "\n",
        "    # Three Convolutional Layers\n",
        "    x = Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(x)\n",
        "    x = Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(x)\n",
        "    x = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n",
        "\n",
        "    # Flatten Layer\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = Dense(units=4096, activation='relu')(x)\n",
        "    x = Dense(units=4096, activation='relu')(x)\n",
        "    output_layer = Dense(units=1000, activation='softmax')(x)  # Assuming 1000 classes for ImageNet\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Assuming SIZE_X and SIZE_Y are defined elsewhere\n",
        "model = create_alexnet(input_shape=(SIZE_X, SIZE_Y, 3))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koppLPx0Oyjt",
        "outputId": "3547a81c-c439-4945-afd9-51fef9976e2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train-----> (7000, 1000)\n",
            "Shape of X_val-----> (1500, 1000)\n",
            "Shape of X_test-----> (1500, 1000)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = get_features(model, train_it, validate_it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J00cmAFnOzMF",
        "outputId": "ee6fead5-a144-4337-c57a-34b36064d78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after reshaping------->\n",
            "X train-------> (7000, 1000)\n",
            "X val--------> (1500, 1000)\n",
            "X test--------> (1500, 1000)\n",
            "Epoch 1/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6769 - accuracy: 0.5716 - val_loss: 0.6859 - val_accuracy: 0.6200\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6453 - accuracy: 0.6264 - val_loss: 0.6568 - val_accuracy: 0.6700\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6298 - accuracy: 0.6461 - val_loss: 0.6409 - val_accuracy: 0.6586\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6264 - accuracy: 0.6459 - val_loss: 0.6249 - val_accuracy: 0.6693\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.6183 - accuracy: 0.6579 - val_loss: 0.6106 - val_accuracy: 0.6764\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.6108 - accuracy: 0.6691 - val_loss: 0.6012 - val_accuracy: 0.6850\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6088 - accuracy: 0.6687 - val_loss: 0.6456 - val_accuracy: 0.5929\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6070 - accuracy: 0.6675 - val_loss: 0.6292 - val_accuracy: 0.6379\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.6041 - accuracy: 0.6730 - val_loss: 0.6062 - val_accuracy: 0.6814\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.6028 - accuracy: 0.6721 - val_loss: 0.6848 - val_accuracy: 0.6300\n",
            "Epoch 1/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6007 - accuracy: 0.6737 - val_loss: 0.6119 - val_accuracy: 0.6443\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6029 - accuracy: 0.6746 - val_loss: 0.6103 - val_accuracy: 0.6507\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5917 - accuracy: 0.6841 - val_loss: 0.6636 - val_accuracy: 0.6093\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5926 - accuracy: 0.6823 - val_loss: 0.5908 - val_accuracy: 0.6729\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5954 - accuracy: 0.6809 - val_loss: 0.5793 - val_accuracy: 0.6857\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5938 - accuracy: 0.6834 - val_loss: 0.5680 - val_accuracy: 0.7050\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5827 - accuracy: 0.6891 - val_loss: 0.6980 - val_accuracy: 0.6086\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5884 - accuracy: 0.6829 - val_loss: 0.5934 - val_accuracy: 0.6600\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5825 - accuracy: 0.6870 - val_loss: 0.5673 - val_accuracy: 0.7136\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5871 - accuracy: 0.6832 - val_loss: 0.7900 - val_accuracy: 0.5721\n",
            "Epoch 1/10\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5754 - accuracy: 0.6932 - val_loss: 0.5887 - val_accuracy: 0.6871\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5761 - accuracy: 0.6979 - val_loss: 0.5897 - val_accuracy: 0.6764\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5713 - accuracy: 0.6907 - val_loss: 0.6046 - val_accuracy: 0.6657\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5669 - accuracy: 0.7020 - val_loss: 0.6498 - val_accuracy: 0.6257\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5718 - accuracy: 0.6914 - val_loss: 0.5777 - val_accuracy: 0.7043\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5765 - accuracy: 0.6961 - val_loss: 0.6279 - val_accuracy: 0.6343\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5767 - accuracy: 0.6973 - val_loss: 0.5968 - val_accuracy: 0.6786\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5680 - accuracy: 0.6995 - val_loss: 0.5933 - val_accuracy: 0.6764\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5678 - accuracy: 0.7025 - val_loss: 0.6637 - val_accuracy: 0.6079\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.5691 - accuracy: 0.6980 - val_loss: 0.5920 - val_accuracy: 0.6750\n",
            "Epoch 10: early stopping\n",
            "Epoch 1/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5657 - accuracy: 0.7016 - val_loss: 0.5719 - val_accuracy: 0.6907\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5663 - accuracy: 0.7045 - val_loss: 0.5585 - val_accuracy: 0.7064\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5652 - accuracy: 0.7029 - val_loss: 0.5940 - val_accuracy: 0.6464\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5659 - accuracy: 0.6943 - val_loss: 0.6078 - val_accuracy: 0.6686\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5596 - accuracy: 0.7013 - val_loss: 0.5584 - val_accuracy: 0.7129\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5598 - accuracy: 0.7011 - val_loss: 0.8098 - val_accuracy: 0.6007\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5604 - accuracy: 0.7096 - val_loss: 0.5966 - val_accuracy: 0.6857\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5655 - accuracy: 0.7023 - val_loss: 0.6605 - val_accuracy: 0.6400\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5582 - accuracy: 0.7084 - val_loss: 0.5810 - val_accuracy: 0.6950\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5585 - accuracy: 0.7071 - val_loss: 0.5501 - val_accuracy: 0.7107\n",
            "Epoch 1/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5580 - accuracy: 0.7079 - val_loss: 0.6220 - val_accuracy: 0.6529\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5550 - accuracy: 0.7061 - val_loss: 0.7708 - val_accuracy: 0.6064\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5623 - accuracy: 0.6989 - val_loss: 0.6045 - val_accuracy: 0.6379\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.5595 - accuracy: 0.7025 - val_loss: 0.7408 - val_accuracy: 0.5843\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5564 - accuracy: 0.7070 - val_loss: 0.5470 - val_accuracy: 0.7257\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5528 - accuracy: 0.7139 - val_loss: 0.6340 - val_accuracy: 0.6386\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5619 - accuracy: 0.7055 - val_loss: 0.5842 - val_accuracy: 0.6950\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5556 - accuracy: 0.7096 - val_loss: 0.5561 - val_accuracy: 0.7014\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5475 - accuracy: 0.7146 - val_loss: 0.5596 - val_accuracy: 0.7000\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5487 - accuracy: 0.7123 - val_loss: 0.7429 - val_accuracy: 0.5664\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test = reshape_data(X_train, X_val, X_test)\n",
        "ANN, LR, KNN, SVM, RF, XGB = get_models()\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define number of splits for K-Fold cross-validation\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "# Initialize lists to store performance metrics for each fold\n",
        "accuracy_scores_ANN = []\n",
        "f1_scores_ANN = []\n",
        "accuracy_scores_LR = []\n",
        "f1_scores_LR = []\n",
        "accuracy_scores_KNN = []\n",
        "f1_scores_KNN = []\n",
        "accuracy_scores_SVM = []\n",
        "f1_scores_SVM = []\n",
        "accuracy_scores_RF = []\n",
        "f1_scores_RF = []\n",
        "accuracy_scores_XGB = []\n",
        "f1_scores_XGB = []\n",
        "# Perform K-Fold cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Train ANN model\n",
        "    ANN_fold = fit_ANN(ANN, X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "    # Evaluate ANN model\n",
        "    accuracy_ANN = accuracy_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    f1_ANN = f1_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    accuracy_scores_ANN.append(accuracy_ANN)\n",
        "    f1_scores_ANN.append(f1_ANN)\n",
        "\n",
        "    # Train LR model\n",
        "    LR_fold = fit_model(LR, X_train_fold, y_train_fold)\n",
        "    # Evaluate LR model\n",
        "    accuracy_LR = accuracy_score(y_test, LR_fold.predict(X_test))\n",
        "    accuracy_scores_LR.append(accuracy_LR)\n",
        "    f1_LR=f1_score(y_test, LR_fold.predict(X_test))\n",
        "    f1_scores_LR.append(f1_LR)\n",
        "\n",
        "    # Train KNN model\n",
        "    KNN_fold = fit_model(KNN, X_train_fold, y_train_fold)\n",
        "    # Evaluate KNN model\n",
        "    accuracy_KNN = accuracy_score(y_test, KNN_fold.predict(X_test))\n",
        "    accuracy_scores_KNN.append(accuracy_KNN)\n",
        "    f1_KNN=f1_score(y_test, KNN_fold.predict(X_test))\n",
        "    f1_scores_KNN.append(f1_KNN)\n",
        "\n",
        "    # Train SVM model\n",
        "    SVM_fold = fit_model(SVM, X_train_fold, y_train_fold)\n",
        "    # Evaluate SVM model\n",
        "    accuracy_SVM = accuracy_score(y_test, SVM_fold.predict(X_test))\n",
        "    accuracy_scores_SVM.append(accuracy_SVM)\n",
        "    f1_SVM=f1_score(y_test, SVM_fold.predict(X_test))\n",
        "    f1_scores_SVM.append(f1_SVM)\n",
        "\n",
        "    # Train RF model\n",
        "    RF_fold = fit_model(RF, X_train_fold, y_train_fold)\n",
        "    # Evaluate RF model\n",
        "    accuracy_RF = accuracy_score(y_test, RF_fold.predict(X_test))\n",
        "    accuracy_scores_RF.append(accuracy_RF)\n",
        "    f1_RF=f1_score(y_test, RF_fold.predict(X_test))\n",
        "    f1_scores_RF.append(f1_RF)\n",
        "\n",
        "    # Train XGB model\n",
        "    XGB_fold = fit_model(XGB, X_train_fold, y_train_fold)\n",
        "    # Evaluate XGB model\n",
        "    accuracy_XGB = accuracy_score(y_test, XGB_fold.predict(X_test))\n",
        "    accuracy_scores_XGB.append(accuracy_XGB)\n",
        "    f1_XGB=f1_score(y_test, XGB_fold.predict(X_test))\n",
        "    f1_scores_XGB.append(f1_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c51ppFwM5yyb"
      },
      "outputs": [],
      "source": [
        "average_accuracy_ANN = np.mean(accuracy_scores_ANN)\n",
        "average_f1_ANN = np.mean(f1_scores_ANN)\n",
        "average_accuracy_LR = np.mean(accuracy_scores_LR)\n",
        "average_f1_LR = np.mean(f1_scores_LR)\n",
        "average_accuracy_KNN = np.mean(accuracy_scores_KNN)\n",
        "average_f1_KNN = np.mean(f1_scores_KNN)\n",
        "average_accuracy_SVM = np.mean(accuracy_scores_SVM)\n",
        "average_f1_SVM = np.mean(f1_scores_SVM)\n",
        "average_accuracy_RF = np.mean(accuracy_scores_RF)\n",
        "average_f1_RF = np.mean(f1_scores_RF)\n",
        "average_accuracy_XGB = np.mean(accuracy_scores_XGB)\n",
        "average_f1_XGB = np.mean(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnWZUe456EwL",
        "outputId": "e1641efe-b1ce-46fe-fc8e-957fa9500f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.614, 0.5613333333333334, 0.6806666666666666, 0.73, 0.5906666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR1FiesG8pnS",
        "outputId": "4a5a143b-3084-4c02-e85c-c8e37b7dfbea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.588, 0.5673333333333334, 0.5786666666666667, 0.574, 0.586]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWta5UHWKc_R",
        "outputId": "44c89370-b4a0-45a0-bb64-19f19a447816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.602, 0.6086666666666667, 0.6053333333333333, 0.6073333333333333, 0.6006666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA10LbeaKd5_",
        "outputId": "2e5d97d6-32f9-49a3-bfa4-92a0de528de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5566666666666666, 0.5486666666666666, 0.55, 0.5533333333333333, 0.5566666666666666]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqXkWzQ-Kexi",
        "outputId": "c96b67ee-3b04-40b5-94c5-cba5c2dacbbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.754, 0.7533333333333333, 0.7526666666666667, 0.7713333333333333, 0.7593333333333333]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX6xve-CKfSE",
        "outputId": "852a9f24-5dfc-47be-f514-7f32a1ddd62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.88, 0.8746666666666667, 0.8746666666666667, 0.88, 0.8746666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICmKqC0m7CBU",
        "outputId": "63c31a10-221c-4d50-cf61-cd4fb8b5666d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.7059421025901473, 0.23842592592592593, 0.7206997084548105, 0.731610337972167, 0.3590814196242171]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--jsAx408vFB",
        "outputId": "322fb068-a147-425f-dedf-11ec0ff83dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5896414342629482, 0.5863607393244105, 0.594871794871795, 0.5895953757225434, 0.5778382053025154]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuNkh2pfKmY7",
        "outputId": "a248ce97-946e-492a-ab38-bd53bc2a0a04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5952542372881355, 0.605775688381464, 0.598371777476255, 0.6049631120053655, 0.5955435516542876]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO8LspkCKm3R",
        "outputId": "3c9960b0-9dc5-4d43-aa8d-7442ce72f72c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.573444515715202, 0.5874466788543571, 0.5794392523364486, 0.5822942643391521, 0.5684620376378974]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogXkCoLTKna8",
        "outputId": "89ab0041-b8a2-419b-ecef-153afe874967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.7674858223062382, 0.7690387016229713, 0.7626359564939219, 0.7833228048010108, 0.7707936507936508]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PA4ctR7Kn8K",
        "outputId": "14530ca4-4f10-4271-e9e0-9de63a6a36b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8834196891191709, 0.8777633289986996, 0.877444589308996, 0.884020618556701, 0.8777633289986996]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yym9J3K450H5",
        "outputId": "0ef91c93-606b-4067-8cd5-76bc39f3a8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for ANN model: 0.6353333333333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for ANN model:\", average_accuracy_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CsnV0oK7K-L",
        "outputId": "f1fb7d30-4e44-47fb-d6be-1fda561261a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for ANN model: 0.5511518989134535\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for ANN model:\", average_f1_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkhLc2zeKvT6",
        "outputId": "d27e72ef-c1c2-4846-c702-a4d3bacec6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for LR model: 0.5788\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for LR model:\", average_accuracy_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMjcx3wZKxjQ",
        "outputId": "3b698225-3859-4a6e-aa62-7594bbfb83a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for LR model: 0.5876615098968425\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for LR model:\", average_f1_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twq5xpeyLARU",
        "outputId": "974c998d-b161-400b-d135-7b715f632608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for KNN model: 0.6047999999999999\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for KNN model:\", average_accuracy_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yjeHa-9LCXb",
        "outputId": "d0200417-1f3d-4825-d8b4-5fdaa8c9db93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for KNN model: 0.5999816733611015\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for KNN model:\", average_f1_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttj7roLKLVL2",
        "outputId": "7d4e096e-ee02-4430-f5db-79dded1827a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for SVM model: 0.5530666666666667\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for SVM model:\", average_accuracy_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brQH_pw2LU9V",
        "outputId": "07b8dc62-d246-410d-9e78-57379c83b4e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for SVM model: 0.5782173497766114\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for SVM model:\", average_f1_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abi4Eq5yLc-c",
        "outputId": "1704857d-813f-466f-ad32-d5d28724f299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for RF model: 0.7581333333333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for RF model:\", average_accuracy_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nqHi90QLc7R",
        "outputId": "cc9aa761-b2ef-4f31-f87a-e7b0a467f915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for RF model: 0.7706553872035585\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for RF model:\", average_f1_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzYZOmGILqpz",
        "outputId": "3b244ed5-b634-49e7-d3cb-78e25d1157b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for XGB model: 0.8768\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for XGB model:\", average_accuracy_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q9zE4yxLtAz",
        "outputId": "7c565a94-cbd2-4bf8-a534-248ab89ee5db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for XGB model: 0.8800823109964535\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for XGB model:\", average_f1_XGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frHO81G3oGI4"
      },
      "source": [
        "###**Inception-V3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAqOWAwkthrC"
      },
      "source": [
        "Import all libraries required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAKqzIF8oLJJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from keras.callbacks import EarlyStopping\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvfhDtJ-oOcr",
        "outputId": "ac22e3ff-b6b8-4032-a716-d21d238e9c41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7000 images belonging to 2 classes.\n",
            "Found 3000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"colon_image_sets\"\n",
        "SIZE_X = SIZE_Y = 299\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.3)\n",
        "\n",
        "train_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X,SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='training',\n",
        "                                       seed = 42)\n",
        "\n",
        "validate_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X, SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='validation',\n",
        "                                       seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaysaQ97pngC"
      },
      "outputs": [],
      "source": [
        "def get_features(base_model, train, validate):\n",
        "    X_train = base_model.predict(train)\n",
        "    y_train = train.classes\n",
        "\n",
        "    X_val = base_model.predict(validate)\n",
        "    y_val = validate.classes\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5, shuffle = True)\n",
        "    print('Shape of X_train----->', str(X_train.shape))\n",
        "    print('Shape of X_val----->', str(X_val.shape))\n",
        "    print('Shape of X_test----->', str(X_test.shape))\n",
        "    return (X_train, X_val, X_test, y_train, y_val, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie0s4bwcpoH1"
      },
      "outputs": [],
      "source": [
        "def get_models():\n",
        "    ANN = Sequential()\n",
        "    ANN.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
        "    ANN.add(BatchNormalization())\n",
        "    ANN.add(Dropout(0.2))\n",
        "    ANN.add(Dense(64, activation='relu'))\n",
        "    ANN.add(Dense(32, activation='relu'))\n",
        "    ANN.add(Dense(16, activation='relu'))\n",
        "    ANN.add(Dense(8, activation='relu'))\n",
        "    ANN.add(Dense(len(train_it.class_indices), activation='softmax'))\n",
        "    ANN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    LR = LogisticRegression()\n",
        "\n",
        "    KNN = KNeighborsClassifier(n_neighbors=50)\n",
        "\n",
        "    SVM = SVC(kernel = 'linear')\n",
        "\n",
        "    RF = RandomForestClassifier(n_estimators = 50)\n",
        "\n",
        "    XGB = XGBClassifier(n_estimators = 50, use_label_encoder=False)\n",
        "\n",
        "    return (ANN, LR, KNN, SVM, RF, XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvWmkjZzpq_h"
      },
      "outputs": [],
      "source": [
        "def reshape_data(X_train, X_val, X_test):\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_val = X_val.reshape(X_val.shape[0], -1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    print(\"Shape after reshaping------->\")\n",
        "    print(\"X train------->\", str(X_train.shape))\n",
        "    print(\"X val-------->\", str(X_val.shape))\n",
        "    print(\"X test-------->\", str(X_test.shape))\n",
        "\n",
        "    return (X_train, X_val, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAh32i-SptsB"
      },
      "outputs": [],
      "source": [
        "def fit_ANN(model, X_train, y_train, X_val, y_test):\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_test), epochs=10, verbose=1, callbacks=[es])\n",
        "    return model\n",
        "\n",
        "def fit_model(model, X_train, y_train):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJA8fGV6p12V",
        "outputId": "eb5f1024-4679-47f9-d5d5-cb801833eed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 149, 149, 32  864         ['input_5[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 149, 149, 32  96         ['conv2d_20[0][0]']              \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 147, 147, 32  96         ['conv2d_21[0][0]']              \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 147, 147, 64  192        ['conv2d_22[0][0]']              \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, 73, 73, 64)  0           ['activation_2[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 73, 73, 80)   5120        ['max_pooling2d_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_23[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_24[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooling2D  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 35, 35, 64)   12288       ['max_pooling2d_13[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_28[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 35, 35, 48)   9216        ['max_pooling2d_13[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_26[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_13[0][0]']       \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 35, 35, 64)   12288       ['max_pooling2d_13[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " conv2d_31 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 35, 96)  288         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 35, 32)  96          ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 35, 35, 64)  192         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 35, 35, 48)  144         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 35, 35, 64)  192         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 35, 35, 96)  288         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 35, 35, 64)  192         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 35, 35, 48)  144         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 35, 35, 64)  192         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 35, 35, 96)  288         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 35, 35, 64)  192         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 35, 35, 64)  192         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 35, 35, 96)  288         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 17, 17, 96)  288         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_27[0][0]'] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooling2D  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 17, 17, 128)  384        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 17, 17, 128)  384        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 17, 17, 160)  480        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 17, 17, 160)  480        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " conv2d_74 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 17, 17, 160)  480        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 17, 17, 160)  480        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_93[0][0]']              \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 17, 17, 192)  576        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 17, 17, 192)  576        ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 8, 8, 320)   960         ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 8, 8, 192)   576         ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_15 (MaxPooling2D  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_15[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_100[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_101[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_99[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_102[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_103[0][0]']             \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 8, 8, 320)   960         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 8, 8, 192)   576         ['conv2d_104[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_109[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_106[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_110[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_107[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_108[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_111[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_112[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 8, 8, 320)   960         ['conv2d_105[0][0]']             \n",
            " ormalization)                                                                                    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 8, 8, 192)   576         ['conv2d_113[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=(SIZE_X, SIZE_Y, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY7Red9hp60Z",
        "outputId": "bf0a15f3-fcff-4490-e71e-03b10871177c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train-----> (7000, 8, 8, 2048)\n",
            "Shape of X_val-----> (1500, 8, 8, 2048)\n",
            "Shape of X_test-----> (1500, 8, 8, 2048)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = get_features(model, train_it, validate_it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxRPv3tUp_ne",
        "outputId": "d2e1782e-0ee6-428d-b1a8-a00a62c7c844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after reshaping------->\n",
            "X train-------> (7000, 131072)\n",
            "X val--------> (1500, 131072)\n",
            "X test--------> (1500, 131072)\n",
            "Epoch 1/10\n",
            "175/175 [==============================] - 21s 117ms/step - loss: 0.3634 - accuracy: 0.8396 - val_loss: 1.1546 - val_accuracy: 0.6221\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 19s 107ms/step - loss: 0.1947 - accuracy: 0.9232 - val_loss: 0.2290 - val_accuracy: 0.9093\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 18s 103ms/step - loss: 0.1458 - accuracy: 0.9436 - val_loss: 0.3169 - val_accuracy: 0.8786\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 17s 99ms/step - loss: 0.1126 - accuracy: 0.9570 - val_loss: 0.1656 - val_accuracy: 0.9436\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 17s 97ms/step - loss: 0.1021 - accuracy: 0.9605 - val_loss: 0.2584 - val_accuracy: 0.8943\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 17s 99ms/step - loss: 0.0868 - accuracy: 0.9689 - val_loss: 0.1906 - val_accuracy: 0.9379\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 17s 95ms/step - loss: 0.0734 - accuracy: 0.9745 - val_loss: 0.1984 - val_accuracy: 0.9286\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 16s 94ms/step - loss: 0.0630 - accuracy: 0.9779 - val_loss: 0.1878 - val_accuracy: 0.9414\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 16s 94ms/step - loss: 0.0597 - accuracy: 0.9779 - val_loss: 0.3715 - val_accuracy: 0.8936\n",
            "Epoch 9: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 120s 687ms/step - loss: 0.0838 - accuracy: 0.9702 - val_loss: 0.0342 - val_accuracy: 0.9914\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 122s 697ms/step - loss: 0.0544 - accuracy: 0.9795 - val_loss: 0.1841 - val_accuracy: 0.9371\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 119s 684ms/step - loss: 0.0491 - accuracy: 0.9823 - val_loss: 0.1026 - val_accuracy: 0.9679\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 117s 668ms/step - loss: 0.0563 - accuracy: 0.9787 - val_loss: 1.8310 - val_accuracy: 0.5679\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 113s 646ms/step - loss: 0.0491 - accuracy: 0.9818 - val_loss: 0.0767 - val_accuracy: 0.9686\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 112s 640ms/step - loss: 0.0348 - accuracy: 0.9882 - val_loss: 0.0641 - val_accuracy: 0.9757\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 76s 432ms/step - loss: 0.0636 - accuracy: 0.9757 - val_loss: 0.0595 - val_accuracy: 0.9850\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 76s 437ms/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 0.1075 - val_accuracy: 0.9957\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 76s 438ms/step - loss: 0.0387 - accuracy: 0.9854 - val_loss: 0.3715 - val_accuracy: 0.9707\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 77s 442ms/step - loss: 0.0225 - accuracy: 0.9911 - val_loss: 0.7611 - val_accuracy: 0.9786\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 75s 431ms/step - loss: 0.0413 - accuracy: 0.9846 - val_loss: 1.3947 - val_accuracy: 0.9757\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 74s 425ms/step - loss: 0.0355 - accuracy: 0.9870 - val_loss: 2.4501 - val_accuracy: 0.9693\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 73s 418ms/step - loss: 0.0283 - accuracy: 0.9896 - val_loss: 0.0335 - val_accuracy: 0.9893\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 72s 413ms/step - loss: 0.0278 - accuracy: 0.9907 - val_loss: 0.1202 - val_accuracy: 0.9529\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 72s 411ms/step - loss: 0.0351 - accuracy: 0.9875 - val_loss: 0.0194 - val_accuracy: 0.9914\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 73s 416ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0714 - val_accuracy: 0.9757\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 71s 407ms/step - loss: 0.0298 - accuracy: 0.9889 - val_loss: 0.0281 - val_accuracy: 0.9886\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 70s 402ms/step - loss: 0.0224 - accuracy: 0.9920 - val_loss: 1.0000 - val_accuracy: 0.7736\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 73s 417ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.0447 - val_accuracy: 0.9779\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 72s 411ms/step - loss: 0.0255 - accuracy: 0.9932 - val_loss: 0.0970 - val_accuracy: 0.9643\n",
            "Epoch 8: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 69s 396ms/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 0.0191 - val_accuracy: 0.9943\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 71s 405ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 71s 405ms/step - loss: 0.0239 - accuracy: 0.9909 - val_loss: 0.0566 - val_accuracy: 0.9800\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 70s 399ms/step - loss: 0.0260 - accuracy: 0.9925 - val_loss: 0.0911 - val_accuracy: 0.9600\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 69s 393ms/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.2702 - val_accuracy: 0.9143\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 69s 393ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0490 - val_accuracy: 0.9793\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 69s 396ms/step - loss: 0.0223 - accuracy: 0.9912 - val_loss: 0.0143 - val_accuracy: 0.9950\n",
            "Epoch 7: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test = reshape_data(X_train, X_val, X_test)\n",
        "ANN, LR, KNN, SVM, RF, XGB = get_models()\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define number of splits for K-Fold cross-validation\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "# Initialize lists to store performance metrics for each fold\n",
        "accuracy_scores_ANN = []\n",
        "f1_scores_ANN = []\n",
        "accuracy_scores_LR = []\n",
        "f1_scores_LR = []\n",
        "accuracy_scores_KNN = []\n",
        "f1_scores_KNN = []\n",
        "accuracy_scores_SVM = []\n",
        "f1_scores_SVM = []\n",
        "accuracy_scores_RF = []\n",
        "f1_scores_RF = []\n",
        "accuracy_scores_XGB = []\n",
        "f1_scores_XGB = []\n",
        "# Perform K-Fold cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Train ANN model\n",
        "    ANN_fold = fit_ANN(ANN, X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "    # Evaluate ANN model\n",
        "    accuracy_ANN = accuracy_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    f1_ANN = f1_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    accuracy_scores_ANN.append(accuracy_ANN)\n",
        "    f1_scores_ANN.append(f1_ANN)\n",
        "\n",
        "    # Train LR model\n",
        "    LR_fold = fit_model(LR, X_train_fold, y_train_fold)\n",
        "    # Evaluate LR model\n",
        "    accuracy_LR = accuracy_score(y_test, LR_fold.predict(X_test))\n",
        "    accuracy_scores_LR.append(accuracy_LR)\n",
        "    f1_LR=f1_score(y_test, LR_fold.predict(X_test))\n",
        "    f1_scores_LR.append(f1_LR)\n",
        "\n",
        "    # Train KNN model\n",
        "    KNN_fold = fit_model(KNN, X_train_fold, y_train_fold)\n",
        "    # Evaluate KNN model\n",
        "    accuracy_KNN = accuracy_score(y_test, KNN_fold.predict(X_test))\n",
        "    accuracy_scores_KNN.append(accuracy_KNN)\n",
        "    f1_KNN=f1_score(y_test, KNN_fold.predict(X_test))\n",
        "    f1_scores_KNN.append(f1_KNN)\n",
        "\n",
        "    # Train SVM model\n",
        "    SVM_fold = fit_model(SVM, X_train_fold, y_train_fold)\n",
        "    # Evaluate SVM model\n",
        "    accuracy_SVM = accuracy_score(y_test, SVM_fold.predict(X_test))\n",
        "    accuracy_scores_SVM.append(accuracy_SVM)\n",
        "    f1_SVM=f1_score(y_test, SVM_fold.predict(X_test))\n",
        "    f1_scores_SVM.append(f1_SVM)\n",
        "\n",
        "    # Train RF model\n",
        "    RF_fold = fit_model(RF, X_train_fold, y_train_fold)\n",
        "    # Evaluate RF model\n",
        "    accuracy_RF = accuracy_score(y_test, RF_fold.predict(X_test))\n",
        "    accuracy_scores_RF.append(accuracy_RF)\n",
        "    f1_RF=f1_score(y_test, RF_fold.predict(X_test))\n",
        "    f1_scores_RF.append(f1_RF)\n",
        "\n",
        "    # Train XGB model\n",
        "    XGB_fold = fit_model(XGB, X_train_fold, y_train_fold)\n",
        "    # Evaluate XGB model\n",
        "    accuracy_XGB = accuracy_score(y_test, XGB_fold.predict(X_test))\n",
        "    accuracy_scores_XGB.append(accuracy_XGB)\n",
        "    f1_XGB=f1_score(y_test, XGB_fold.predict(X_test))\n",
        "    f1_scores_XGB.append(f1_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPD2xDdROYxC"
      },
      "outputs": [],
      "source": [
        "average_accuracy_ANN = np.mean(accuracy_scores_ANN)\n",
        "average_f1_ANN = np.mean(f1_scores_ANN)\n",
        "average_accuracy_LR = np.mean(accuracy_scores_LR)\n",
        "average_f1_LR = np.mean(f1_scores_LR)\n",
        "average_accuracy_KNN = np.mean(accuracy_scores_KNN)\n",
        "average_f1_KNN = np.mean(f1_scores_KNN)\n",
        "average_accuracy_SVM = np.mean(accuracy_scores_SVM)\n",
        "average_f1_SVM = np.mean(f1_scores_SVM)\n",
        "average_accuracy_RF = np.mean(accuracy_scores_RF)\n",
        "average_f1_RF = np.mean(f1_scores_RF)\n",
        "average_accuracy_XGB = np.mean(accuracy_scores_XGB)\n",
        "average_f1_XGB = np.mean(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ_KdgKjPH5_",
        "outputId": "35b51510-cb60-4986-8273-e2d38740ae2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8706666666666667, 0.96, 0.9353333333333333, 0.9193333333333333, 0.9586666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFRCuD4jPJKp",
        "outputId": "d029f7f2-1363-4d26-c05a-396be9da665e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9466666666666667, 0.9506666666666667, 0.9533333333333334, 0.9466666666666667, 0.9446666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRPhUHCRPK-X",
        "outputId": "1eaaf0a0-5541-4cee-e690-939b04b27f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.7366666666666667, 0.7373333333333333, 0.75, 0.738, 0.7346666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_utfuw7PQs7",
        "outputId": "611efc48-7c6f-426b-fd63-c6ea22304203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9653333333333334, 0.9613333333333334, 0.9606666666666667, 0.9613333333333334, 0.9626666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92ILJizmPSaa",
        "outputId": "51c66fa9-9997-4025-fc7f-80b0f3b3a35f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9046666666666666, 0.8966666666666666, 0.8953333333333333, 0.9046666666666666, 0.8933333333333333]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5wkxCYSPUY9",
        "outputId": "85afea5b-2394-4246-8463-8b095b9239fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.942, 0.9326666666666666, 0.924, 0.9413333333333334, 0.938]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJQKJ-D8PWbk",
        "outputId": "8edff0c4-e10a-4efe-97c6-e79679db593f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8835534213685473, 0.9589603283173734, 0.9362261669953977, 0.9242329367564184, 0.9581646423751687]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHz3uzfmPX8s",
        "outputId": "8d7a9fa0-ff3e-4cc9-80ed-321b9f82700a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9462365591397849, 0.9507323568575233, 0.9531459170013385, 0.946164199192463, 0.9445557782231128]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTVCRoNKPZh6",
        "outputId": "6c47ef86-eccf-4f6b-d289-2e5440a987b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.6457399103139013, 0.6469534050179211, 0.6696035242290749, 0.6494201605709188, 0.6420863309352518]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKSeXYyLPbNn",
        "outputId": "0389a256-a94d-4701-c78b-9df85d2ac98c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9653794940079894, 0.9614873837981408, 0.9606404269513008, 0.961021505376344, 0.9628647214854111]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-8aMEvDPeUc",
        "outputId": "ccd0bc0e-323f-4836-cb32-c9359435be8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.90473017988008, 0.8972829688535453, 0.895123580494322, 0.9044756179024716, 0.8941798941798942]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V6LsrKBPeyL",
        "outputId": "b852f626-79ec-43cf-e38f-10a5a7207cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9421157684630739, 0.9326217478318879, 0.9243027888446216, 0.9414114513981358, 0.93812375249501]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ons_3R3tPgK5",
        "outputId": "3dfe26eb-7fbe-4421-ae83-2ce1f9ebe743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for ANN model: 0.9288000000000001\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for ANN model:\", average_accuracy_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytHrGq5oPiPF",
        "outputId": "b4744026-09dc-4b2e-bb9e-4439c0d01fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for ANN model: 0.9322274991625811\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for ANN model:\", average_f1_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0BwosKJPjyQ",
        "outputId": "d7a0d507-1f2e-4459-812c-e2f9231ef684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for LR model: 0.9484\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for LR model:\", average_accuracy_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBkFWqllPoFP",
        "outputId": "fafa9a19-dc72-4fde-80ac-93cc54c7ecc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for LR model: 0.9481669620828445\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for LR model:\", average_f1_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Srx0ixDtPpFw",
        "outputId": "c37ff7bc-92d7-4175-ebcc-b99c6ed6eaaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for KNN model: 0.7393333333333334\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for KNN model:\", average_accuracy_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8HjilRwPq1N",
        "outputId": "8f1a4efa-de60-4f34-9773-79031e9afbcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for KNN model: 0.6507606662134136\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for KNN model:\", average_f1_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFPKlNh4PseD",
        "outputId": "d1ef7e87-bb44-421b-8bfe-866594c737e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for SVM model: 0.9622666666666666\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for SVM model:\", average_accuracy_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5OXeVrNPt_m",
        "outputId": "2c4cb2bf-591d-4c8c-db63-4fbf4c8213d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for SVM model: 0.9622787063238374\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for SVM model:\", average_f1_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vvQbZipPvyG",
        "outputId": "35a1f9c9-c214-4c5f-e6f6-932df8bb1ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for RF model: 0.8989333333333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for RF model:\", average_accuracy_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eamf0uxHPyKQ",
        "outputId": "f07eda28-8aa6-4046-ec89-c3f9d6f7f622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for RF model: 0.8991584482620626\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for RF model:\", average_f1_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vZs8uC-PzwG",
        "outputId": "32cca16e-c65d-4814-9c0b-27c701227461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for XGB model: 0.9356\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for XGB model:\", average_accuracy_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaiVkD-IP1gW",
        "outputId": "446b441c-b283-4ab8-b7ca-6c0da63c5681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for XGB model: 0.9357151018065458\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for XGB model:\", average_f1_XGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG1a6rx3KesO"
      },
      "source": [
        "###**VGG-16**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOqdf_mLG8bE"
      },
      "source": [
        "Import all libraries required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wWFwwVDyCWW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from keras.callbacks import EarlyStopping\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEpFhhvqQuxQ",
        "outputId": "71c05d66-bcd7-4c1e-beb7-478a1c0b9fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7000 images belonging to 2 classes.\n",
            "Found 3000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"colon_image_sets\"\n",
        "SIZE_X = SIZE_Y = 224\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.3)\n",
        "\n",
        "train_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X,SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='training',\n",
        "                                       seed = 42)\n",
        "\n",
        "validate_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X, SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='validation',\n",
        "                                       seed = 42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZjsF-VOQvc3"
      },
      "outputs": [],
      "source": [
        "def get_features(base_model, train, validate):\n",
        "    X_train = base_model.predict(train)\n",
        "    y_train = train.classes\n",
        "\n",
        "    X_val = base_model.predict(validate)\n",
        "    y_val = validate.classes\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5, shuffle = True)\n",
        "    print('Shape of X_train----->', str(X_train.shape))\n",
        "    print('Shape of X_val----->', str(X_val.shape))\n",
        "    print('Shape of X_test----->', str(X_test.shape))\n",
        "    return (X_train, X_val, X_test, y_train, y_val, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUCOuQjTQzMV"
      },
      "outputs": [],
      "source": [
        "def get_models():\n",
        "    ANN = Sequential()\n",
        "    ANN.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
        "    ANN.add(BatchNormalization())\n",
        "    ANN.add(Dropout(0.2))\n",
        "    ANN.add(Dense(64, activation='relu'))\n",
        "    ANN.add(Dense(32, activation='relu'))\n",
        "    ANN.add(Dense(16, activation='relu'))\n",
        "    ANN.add(Dense(8, activation='relu'))\n",
        "    ANN.add(Dense(len(train_it.class_indices), activation='softmax'))\n",
        "    ANN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    LR = LogisticRegression()\n",
        "\n",
        "    KNN = KNeighborsClassifier(n_neighbors=50)\n",
        "\n",
        "    SVM = SVC(kernel = 'linear')\n",
        "\n",
        "    RF = RandomForestClassifier(n_estimators = 50)\n",
        "\n",
        "    XGB = XGBClassifier(n_estimators = 50, use_label_encoder=False)\n",
        "\n",
        "    return (ANN, LR, KNN, SVM, RF, XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WTNN5bZQ3mI"
      },
      "outputs": [],
      "source": [
        "def reshape_data(X_train, X_val, X_test):\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_val = X_val.reshape(X_val.shape[0], -1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    print(\"Shape after reshaping------->\")\n",
        "    print(\"X train------->\", str(X_train.shape))\n",
        "    print(\"X val-------->\", str(X_val.shape))\n",
        "    print(\"X test-------->\", str(X_test.shape))\n",
        "\n",
        "    return (X_train, X_val, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY1H_Fx2Q-CQ"
      },
      "outputs": [],
      "source": [
        "def fit_ANN(model, X_train, y_train, X_val, y_test):\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_test), epochs=10, verbose=1, callbacks=[es])\n",
        "    return model\n",
        "\n",
        "def fit_model(model, X_train, y_train):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdR2Xsy7REzm",
        "outputId": "59fcec6c-83d9-46c2-e74e-020cbe8e22e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "base_model = VGG16(include_top=False, input_shape=(SIZE_X, SIZE_Y, 3), weights='imagenet')\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZOa4QtQRL4a",
        "outputId": "19e2a3ee-63da-4a67-b5f3-fa19c02d234e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train-----> (7000, 7, 7, 512)\n",
            "Shape of X_val-----> (1500, 7, 7, 512)\n",
            "Shape of X_test-----> (1500, 7, 7, 512)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = get_features(model, train_it, validate_it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp6YAF_FRNhr",
        "outputId": "f4c82ce2-9438-4dbf-c89a-a24d3d6a4df2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after reshaping------->\n",
            "X train-------> (7000, 25088)\n",
            "X val--------> (1500, 25088)\n",
            "X test--------> (1500, 25088)\n",
            "Epoch 1/10\n",
            "175/175 [==============================] - 15s 83ms/step - loss: 0.0669 - accuracy: 0.9784 - val_loss: 0.0457 - val_accuracy: 0.9957\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 14s 83ms/step - loss: 0.0121 - accuracy: 0.9955 - val_loss: 0.0229 - val_accuracy: 0.9907\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 14s 81ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.0153 - val_accuracy: 0.9943\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 14s 81ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0298 - val_accuracy: 0.9929\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 15s 83ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.0211 - val_accuracy: 0.9936\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 14s 80ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0115 - val_accuracy: 0.9971\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 14s 79ms/step - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.0703 - val_accuracy: 0.9807\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 14s 81ms/step - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.0118 - val_accuracy: 0.9964\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 13s 75ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0214 - val_accuracy: 0.9950\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 13s 77ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.0128 - val_accuracy: 0.9957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 14s 83ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0229 - val_accuracy: 0.9986\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 15s 84ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0628 - val_accuracy: 0.9986\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 14s 80ms/step - loss: 5.7788e-04 - accuracy: 0.9998 - val_loss: 0.1215 - val_accuracy: 0.9986\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 14s 80ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.3544 - val_accuracy: 0.9979\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 14s 79ms/step - loss: 9.5337e-04 - accuracy: 0.9996 - val_loss: 0.3908 - val_accuracy: 0.9986\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 14s 80ms/step - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.5547 - val_accuracy: 0.9993\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 14s 78ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 14s 80ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.0032 - val_accuracy: 0.9986\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 14s 77ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 14s 79ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0155 - val_accuracy: 0.9979\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 14s 80ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0328 - val_accuracy: 0.9986\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 13s 77ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0168 - val_accuracy: 0.9993\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 13s 75ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9993\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 13s 76ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0396 - val_accuracy: 0.9986\n",
            "Epoch 8: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 14s 81ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0543 - val_accuracy: 0.9971\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 15s 83ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0591 - val_accuracy: 0.9971\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 14s 83ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1967 - val_accuracy: 0.9971\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 14s 83ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.1479 - val_accuracy: 0.9971\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 14s 82ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.0539 - val_accuracy: 0.9986\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 15s 86ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0123 - val_accuracy: 0.9993\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 15s 83ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0156 - val_accuracy: 0.9979\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 14s 80ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.0613 - val_accuracy: 0.9986\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 14s 81ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0939 - val_accuracy: 0.9986\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 15s 84ms/step - loss: 2.6866e-04 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 15s 84ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0198 - val_accuracy: 0.9986\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 13s 75ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0467 - val_accuracy: 0.9979\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 13s 76ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.1497 - val_accuracy: 0.9971\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 14s 79ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.4039 - val_accuracy: 0.9964\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 14s 80ms/step - loss: 3.1033e-04 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.9964\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 14s 79ms/step - loss: 7.2328e-04 - accuracy: 0.9998 - val_loss: 0.9061 - val_accuracy: 0.9964\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test = reshape_data(X_train, X_val, X_test)\n",
        "ANN, LR, KNN, SVM, RF, XGB = get_models()\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define number of splits for K-Fold cross-validation\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "# Initialize lists to store performance metrics for each fold\n",
        "accuracy_scores_ANN = []\n",
        "f1_scores_ANN = []\n",
        "accuracy_scores_LR = []\n",
        "f1_scores_LR = []\n",
        "accuracy_scores_KNN = []\n",
        "f1_scores_KNN = []\n",
        "accuracy_scores_SVM = []\n",
        "f1_scores_SVM = []\n",
        "accuracy_scores_RF = []\n",
        "f1_scores_RF = []\n",
        "accuracy_scores_XGB = []\n",
        "f1_scores_XGB = []\n",
        "# Perform K-Fold cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Train ANN model\n",
        "    ANN_fold = fit_ANN(ANN, X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "    # Evaluate ANN model\n",
        "    accuracy_ANN = accuracy_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    f1_ANN = f1_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    accuracy_scores_ANN.append(accuracy_ANN)\n",
        "    f1_scores_ANN.append(f1_ANN)\n",
        "\n",
        "    # Train LR model\n",
        "    LR_fold = fit_model(LR, X_train_fold, y_train_fold)\n",
        "    # Evaluate LR model\n",
        "    accuracy_LR = accuracy_score(y_test, LR_fold.predict(X_test))\n",
        "    accuracy_scores_LR.append(accuracy_LR)\n",
        "    f1_LR=f1_score(y_test, LR_fold.predict(X_test))\n",
        "    f1_scores_LR.append(f1_LR)\n",
        "\n",
        "    # Train KNN model\n",
        "    KNN_fold = fit_model(KNN, X_train_fold, y_train_fold)\n",
        "    # Evaluate KNN model\n",
        "    accuracy_KNN = accuracy_score(y_test, KNN_fold.predict(X_test))\n",
        "    accuracy_scores_KNN.append(accuracy_KNN)\n",
        "    f1_KNN=f1_score(y_test, KNN_fold.predict(X_test))\n",
        "    f1_scores_KNN.append(f1_KNN)\n",
        "\n",
        "    # Train SVM model\n",
        "    SVM_fold = fit_model(SVM, X_train_fold, y_train_fold)\n",
        "    # Evaluate SVM model\n",
        "    accuracy_SVM = accuracy_score(y_test, SVM_fold.predict(X_test))\n",
        "    accuracy_scores_SVM.append(accuracy_SVM)\n",
        "    f1_SVM=f1_score(y_test, SVM_fold.predict(X_test))\n",
        "    f1_scores_SVM.append(f1_SVM)\n",
        "\n",
        "    # Train RF model\n",
        "    RF_fold = fit_model(RF, X_train_fold, y_train_fold)\n",
        "    # Evaluate RF model\n",
        "    accuracy_RF = accuracy_score(y_test, RF_fold.predict(X_test))\n",
        "    accuracy_scores_RF.append(accuracy_RF)\n",
        "    f1_RF=f1_score(y_test, RF_fold.predict(X_test))\n",
        "    f1_scores_RF.append(f1_RF)\n",
        "\n",
        "    # Train XGB model\n",
        "    XGB_fold = fit_model(XGB, X_train_fold, y_train_fold)\n",
        "    # Evaluate XGB model\n",
        "    accuracy_XGB = accuracy_score(y_test, XGB_fold.predict(X_test))\n",
        "    accuracy_scores_XGB.append(accuracy_XGB)\n",
        "    f1_XGB=f1_score(y_test, XGB_fold.predict(X_test))\n",
        "    f1_scores_XGB.append(f1_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAJi6v32Oa4D"
      },
      "outputs": [],
      "source": [
        "average_accuracy_ANN = np.mean(accuracy_scores_ANN)\n",
        "average_f1_ANN = np.mean(f1_scores_ANN)\n",
        "average_accuracy_LR = np.mean(accuracy_scores_LR)\n",
        "average_f1_LR = np.mean(f1_scores_LR)\n",
        "average_accuracy_KNN = np.mean(accuracy_scores_KNN)\n",
        "average_f1_KNN = np.mean(f1_scores_KNN)\n",
        "average_accuracy_SVM = np.mean(accuracy_scores_SVM)\n",
        "average_f1_SVM = np.mean(f1_scores_SVM)\n",
        "average_accuracy_RF = np.mean(accuracy_scores_RF)\n",
        "average_f1_RF = np.mean(f1_scores_RF)\n",
        "average_accuracy_XGB = np.mean(accuracy_scores_XGB)\n",
        "average_f1_XGB = np.mean(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czWGTI3MQHUR",
        "outputId": "9d4f7442-c02b-4654-fb9d-6b958898cd54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9946666666666667, 0.9966666666666667, 0.9946666666666667, 0.9966666666666667, 0.9973333333333333]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeVeB5Q_QKGC",
        "outputId": "e8114cb2-847c-4457-e206-b5452f7c2f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9946666666666667, 0.9926666666666667, 0.9946666666666667, 0.9946666666666667, 0.9953333333333333]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BCqc1ZNQLbc",
        "outputId": "7641560a-84b1-4148-bf3e-b4dfc826729f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.612, 0.6293333333333333, 0.618, 0.616, 0.6093333333333333]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_LEw4AcQM_g",
        "outputId": "037f37a3-8b5a-4922-a070-0b9d44daef50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9953333333333333, 0.9926666666666667, 0.9946666666666667, 0.9926666666666667, 0.9946666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9qK-vgJQOiQ",
        "outputId": "9da7800b-986e-44ca-f11c-490683090831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.982, 0.9833333333333333, 0.9833333333333333, 0.9873333333333333, 0.9833333333333333]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5ZnEK6sQQBc",
        "outputId": "4e06387e-9b7c-457a-cdd1-788778a1ee5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9853333333333333, 0.9853333333333333, 0.986, 0.9873333333333333, 0.9866666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di_cmCWqQRc6",
        "outputId": "9f78463c-f0e7-4ce6-f0de-2b750de4276c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9946018893387315, 0.9966329966329965, 0.9946018893387315, 0.9966284558327714, 0.9973082099596231]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_fz7MyUQTQT",
        "outputId": "9ad8907b-92cd-43ed-b53e-d1fdfa4194b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9946091644204853, 0.9925925925925926, 0.9946091644204853, 0.9946164199192463, 0.9952861952861952]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDms_DULQWZB",
        "outputId": "d382daad-8a03-4bd8-a3f0-19dfb41080a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.3561946902654867, 0.4021505376344086, 0.3723986856516977, 0.36703296703296706, 0.3488888888888889]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQfC-0IpQZ76",
        "outputId": "239fd7a1-3f13-444e-c84a-c61dad449d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.99527983816588, 0.9925826028320971, 0.9946018893387315, 0.9925925925925926, 0.9946091644204853]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSNexjsmQc04",
        "outputId": "17121c9f-9cc6-47c2-da32-2f3e73b325b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9817444219066935, 0.9830966869506425, 0.9830278343516633, 0.9871708305199188, 0.9830508474576272]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLEgyZnEQgth",
        "outputId": "17144856-6d9e-40b8-c560-5258d87de65b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9851150202976996, 0.9851150202976996, 0.9858203916272789, 0.987136086662153, 0.9864314789687924]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wME7ETVCQiPK",
        "outputId": "326e0baf-f68b-4f31-d0ad-408e667c6315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for ANN model: 0.9960000000000001\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for ANN model:\", average_accuracy_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRFGoGDTQi8P",
        "outputId": "dfdfc2da-7c92-4312-fa2d-9f2006cb31e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for ANN model: 0.9959546882205708\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for ANN model:\", average_f1_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HGFBH3MQkQ3",
        "outputId": "d35908d9-96be-4271-eebb-881d0c77dc43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for LR model: 0.9944000000000001\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for LR model:\", average_accuracy_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHy7hSs9Ql70",
        "outputId": "cde8451e-9e5c-4db9-ca7d-1fa17904b438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for LR model: 0.994342707327801\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for LR model:\", average_f1_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LiJ39-QQqLC",
        "outputId": "06aebcd1-ab87-4ffa-9438-1457273c8d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for KNN model: 0.6169333333333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for KNN model:\", average_accuracy_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IiBpi9nQrAA",
        "outputId": "8d9633b1-7261-4dea-fdc0-37b58856be17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for KNN model: 0.36933315389468985\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for KNN model:\", average_f1_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19_GCGFlQsmj",
        "outputId": "503fd507-ebf8-4af0-c15e-5572837dd035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for SVM model: 0.994\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for SVM model:\", average_accuracy_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9ZDJRfrQukN",
        "outputId": "2d0e6bc6-0a60-422b-bf44-3d293c5dc8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for SVM model: 0.9939332174699572\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for SVM model:\", average_f1_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nr1ITVXQyUW",
        "outputId": "8a597f72-c202-4fbe-b948-e9c171d4dd2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for RF model: 0.9838666666666667\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for RF model:\", average_accuracy_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdrJ6DgOQ0NU",
        "outputId": "8c6c6be6-a765-40da-ddf3-b831662d32c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for RF model: 0.983618124237309\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for RF model:\", average_f1_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X1-SWp4Q1qz",
        "outputId": "abccaa9e-c194-4f5a-934f-cdd9786f142c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for XGB model: 0.9861333333333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for XGB model:\", average_accuracy_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veLYxQDgQ3Ja",
        "outputId": "52892074-c0ae-41cf-ab68-43c20a36cc93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for XGB model: 0.9859235995707246\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for XGB model:\", average_f1_XGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMhJO0pTuDE0"
      },
      "source": [
        "###**ResNet-50**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PWdfYhTuRiS"
      },
      "source": [
        "Import all libraries required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhBYcdPUuHGm"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from keras.callbacks import EarlyStopping\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pNXnlbRuU9f",
        "outputId": "1a304dce-0078-448e-dffa-6ba02c36f107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7000 images belonging to 2 classes.\n",
            "Found 3000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"colon_image_sets\"\n",
        "SIZE_X = SIZE_Y = 224\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.3)\n",
        "\n",
        "train_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X,SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='training',\n",
        "                                       seed = 42)\n",
        "\n",
        "validate_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X, SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='validation',\n",
        "                                       seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9webbL01uW0K"
      },
      "outputs": [],
      "source": [
        "def get_features(base_model, train, validate):\n",
        "    X_train = base_model.predict(train)\n",
        "    y_train = train.classes\n",
        "\n",
        "    X_val = base_model.predict(validate)\n",
        "    y_val = validate.classes\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5, shuffle = True)\n",
        "    print('Shape of X_train----->', str(X_train.shape))\n",
        "    print('Shape of X_val----->', str(X_val.shape))\n",
        "    print('Shape of X_test----->', str(X_test.shape))\n",
        "    return (X_train, X_val, X_test, y_train, y_val, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4ZBI1FVuYso"
      },
      "outputs": [],
      "source": [
        "def get_models():\n",
        "    ANN = Sequential()\n",
        "    ANN.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
        "    ANN.add(BatchNormalization())\n",
        "    ANN.add(Dropout(0.2))\n",
        "    ANN.add(Dense(64, activation='relu'))\n",
        "    ANN.add(Dense(32, activation='relu'))\n",
        "    ANN.add(Dense(16, activation='relu'))\n",
        "    ANN.add(Dense(8, activation='relu'))\n",
        "    ANN.add(Dense(len(train_it.class_indices), activation='softmax'))\n",
        "    ANN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    LR = LogisticRegression()\n",
        "\n",
        "    KNN = KNeighborsClassifier(n_neighbors=50)\n",
        "\n",
        "    SVM = SVC(kernel = 'linear')\n",
        "\n",
        "    RF = RandomForestClassifier(n_estimators = 50)\n",
        "\n",
        "    XGB = XGBClassifier(n_estimators = 50, use_label_encoder=False)\n",
        "\n",
        "    return (ANN, LR, KNN, SVM, RF, XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPSGVXaaua6H"
      },
      "outputs": [],
      "source": [
        "def reshape_data(X_train, X_val, X_test):\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_val = X_val.reshape(X_val.shape[0], -1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    print(\"Shape after reshaping------->\")\n",
        "    print(\"X train------->\", str(X_train.shape))\n",
        "    print(\"X val-------->\", str(X_val.shape))\n",
        "    print(\"X test-------->\", str(X_test.shape))\n",
        "\n",
        "    return (X_train, X_val, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcgVNFaBuciQ"
      },
      "outputs": [],
      "source": [
        "def fit_ANN(model, X_train, y_train, X_val, y_test):\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_test), epochs=10, verbose=1, callbacks=[es])\n",
        "    return model\n",
        "\n",
        "def fit_model(model, X_train, y_train):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrRZVwUFufni",
        "outputId": "357884f3-3aec-4a2c-f0f1-c5af713e7857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(SIZE_X, SIZE_Y, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SSujtFHuoVp",
        "outputId": "e4b84190-894a-4bcf-aaf6-83dfb9fe1d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train-----> (7000, 7, 7, 2048)\n",
            "Shape of X_val-----> (1500, 7, 7, 2048)\n",
            "Shape of X_test-----> (1500, 7, 7, 2048)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = get_features(model, train_it, validate_it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNvRCH5Bup3w",
        "outputId": "1f27e1d0-c55d-4646-cf0d-3484a3dec9b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after reshaping------->\n",
            "X train-------> (7000, 100352)\n",
            "X val--------> (1500, 100352)\n",
            "X test--------> (1500, 100352)\n",
            "Epoch 1/10\n",
            "175/175 [==============================] - 53s 300ms/step - loss: 0.0559 - accuracy: 0.9804 - val_loss: 0.0434 - val_accuracy: 0.9821\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 49s 281ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0147 - val_accuracy: 0.9936\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 50s 285ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0204 - val_accuracy: 0.9936\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 50s 288ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 0.0162 - val_accuracy: 0.9950\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 50s 287ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0069 - val_accuracy: 0.9957\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 50s 286ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0131 - val_accuracy: 0.9979\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 50s 285ms/step - loss: 0.0100 - accuracy: 0.9962 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 48s 277ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 7.6836e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 49s 282ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0108 - val_accuracy: 0.9971\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 49s 280ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0030 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 39s 224ms/step - loss: 0.0086 - accuracy: 0.9962 - val_loss: 0.0309 - val_accuracy: 0.9986\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 40s 226ms/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 0.0885 - val_accuracy: 0.9986\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 40s 227ms/step - loss: 7.5287e-04 - accuracy: 0.9998 - val_loss: 0.2897 - val_accuracy: 0.9986\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 40s 227ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.3987 - val_accuracy: 0.9979\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 39s 224ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.1798 - val_accuracy: 0.9986\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 40s 231ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1902 - val_accuracy: 0.9986\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 40s 231ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0059 - val_accuracy: 0.9986\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 40s 227ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0538 - val_accuracy: 0.9986\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 41s 237ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0720 - val_accuracy: 0.9993\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 40s 228ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 0.2105 - val_accuracy: 0.9993\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 40s 232ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.4183 - val_accuracy: 0.9993\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 41s 234ms/step - loss: 8.4341e-04 - accuracy: 0.9998 - val_loss: 0.3504 - val_accuracy: 0.9993\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 41s 234ms/step - loss: 7.0007e-05 - accuracy: 1.0000 - val_loss: 1.1115e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 41s 236ms/step - loss: 5.3308e-04 - accuracy: 0.9998 - val_loss: 7.4211e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 42s 239ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 42s 239ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 3.6099e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 41s 237ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 2.4971e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 41s 236ms/step - loss: 3.8070e-04 - accuracy: 0.9998 - val_loss: 1.1771e-04 - val_accuracy: 1.0000\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 42s 240ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0417 - val_accuracy: 0.9993\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 41s 236ms/step - loss: 1.8969e-04 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9993\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 42s 238ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0676 - val_accuracy: 0.9993\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 41s 232ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 0.0146 - val_accuracy: 0.9993\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 41s 234ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0809 - val_accuracy: 0.9993\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 41s 237ms/step - loss: 0.0044 - accuracy: 0.9977 - val_loss: 8.1696e-04 - val_accuracy: 0.9993\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 43s 245ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 4.3257e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 41s 237ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0251 - val_accuracy: 0.9993\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 42s 242ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0479 - val_accuracy: 0.9993\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 42s 238ms/step - loss: 7.5833e-04 - accuracy: 0.9998 - val_loss: 0.0498 - val_accuracy: 0.9993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test = reshape_data(X_train, X_val, X_test)\n",
        "ANN, LR, KNN, SVM, RF, XGB = get_models()\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define number of splits for K-Fold cross-validation\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "# Initialize lists to store performance metrics for each fold\n",
        "accuracy_scores_ANN = []\n",
        "f1_scores_ANN = []\n",
        "accuracy_scores_LR = []\n",
        "f1_scores_LR = []\n",
        "accuracy_scores_KNN = []\n",
        "f1_scores_KNN = []\n",
        "accuracy_scores_SVM = []\n",
        "f1_scores_SVM = []\n",
        "accuracy_scores_RF = []\n",
        "f1_scores_RF = []\n",
        "accuracy_scores_XGB = []\n",
        "f1_scores_XGB = []\n",
        "# Perform K-Fold cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Train ANN model\n",
        "    ANN_fold = fit_ANN(ANN, X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "    # Evaluate ANN model\n",
        "    accuracy_ANN = accuracy_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    f1_ANN = f1_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    accuracy_scores_ANN.append(accuracy_ANN)\n",
        "    f1_scores_ANN.append(f1_ANN)\n",
        "\n",
        "    # Train LR model\n",
        "    LR_fold = fit_model(LR, X_train_fold, y_train_fold)\n",
        "    # Evaluate LR model\n",
        "    accuracy_LR = accuracy_score(y_test, LR_fold.predict(X_test))\n",
        "    accuracy_scores_LR.append(accuracy_LR)\n",
        "    f1_LR=f1_score(y_test, LR_fold.predict(X_test))\n",
        "    f1_scores_LR.append(f1_LR)\n",
        "\n",
        "    # Train KNN model\n",
        "    KNN_fold = fit_model(KNN, X_train_fold, y_train_fold)\n",
        "    # Evaluate KNN model\n",
        "    accuracy_KNN = accuracy_score(y_test, KNN_fold.predict(X_test))\n",
        "    accuracy_scores_KNN.append(accuracy_KNN)\n",
        "    f1_KNN=f1_score(y_test, KNN_fold.predict(X_test))\n",
        "    f1_scores_KNN.append(f1_KNN)\n",
        "\n",
        "    # Train SVM model\n",
        "    SVM_fold = fit_model(SVM, X_train_fold, y_train_fold)\n",
        "    # Evaluate SVM model\n",
        "    accuracy_SVM = accuracy_score(y_test, SVM_fold.predict(X_test))\n",
        "    accuracy_scores_SVM.append(accuracy_SVM)\n",
        "    f1_SVM=f1_score(y_test, SVM_fold.predict(X_test))\n",
        "    f1_scores_SVM.append(f1_SVM)\n",
        "\n",
        "    # Train RF model\n",
        "    RF_fold = fit_model(RF, X_train_fold, y_train_fold)\n",
        "    # Evaluate RF model\n",
        "    accuracy_RF = accuracy_score(y_test, RF_fold.predict(X_test))\n",
        "    accuracy_scores_RF.append(accuracy_RF)\n",
        "    f1_RF=f1_score(y_test, RF_fold.predict(X_test))\n",
        "    f1_scores_RF.append(f1_RF)\n",
        "\n",
        "    # Train XGB model\n",
        "    XGB_fold = fit_model(XGB, X_train_fold, y_train_fold)\n",
        "    # Evaluate XGB model\n",
        "    accuracy_XGB = accuracy_score(y_test, XGB_fold.predict(X_test))\n",
        "    accuracy_scores_XGB.append(accuracy_XGB)\n",
        "    f1_XGB=f1_score(y_test, XGB_fold.predict(X_test))\n",
        "    f1_scores_XGB.append(f1_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fsKE30POceG"
      },
      "outputs": [],
      "source": [
        "average_accuracy_ANN = np.mean(accuracy_scores_ANN)\n",
        "average_f1_ANN = np.mean(f1_scores_ANN)\n",
        "average_accuracy_LR = np.mean(accuracy_scores_LR)\n",
        "average_f1_LR = np.mean(f1_scores_LR)\n",
        "average_accuracy_KNN = np.mean(accuracy_scores_KNN)\n",
        "average_f1_KNN = np.mean(f1_scores_KNN)\n",
        "average_accuracy_SVM = np.mean(accuracy_scores_SVM)\n",
        "average_f1_SVM = np.mean(f1_scores_SVM)\n",
        "average_accuracy_RF = np.mean(accuracy_scores_RF)\n",
        "average_f1_RF = np.mean(f1_scores_RF)\n",
        "average_accuracy_XGB = np.mean(accuracy_scores_XGB)\n",
        "average_f1_XGB = np.mean(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyAxxcxmOu_v",
        "outputId": "024114ac-ecde-4cfc-8e8b-dd29765ebe49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9986666666666667, 0.998, 0.998, 0.9993333333333333, 0.9986666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpo4AseDOuy1",
        "outputId": "2ce8aea4-c808-4e77-d87d-a657f2eb45dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9993333333333333, 0.9993333333333333, 0.998, 0.9986666666666667, 0.9986666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gFYG4R0Oujd",
        "outputId": "49fc5b9d-9f61-4f90-bc7b-cb7f2ac406b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8833333333333333, 0.89, 0.8886666666666667, 0.8846666666666667, 0.8846666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuRMucY9OuUI",
        "outputId": "df64de7c-3ed0-4c07-ccef-6e5a60c00a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9986666666666667, 0.9986666666666667, 0.9986666666666667, 0.9986666666666667, 0.9986666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXXz0x_HOt9E",
        "outputId": "9a01d46e-efb8-48dd-9b8f-b7974a19b197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9846666666666667, 0.982, 0.9793333333333333, 0.984, 0.9826666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRHBPjlyOtci",
        "outputId": "e188192c-d578-423d-d7ca-bb4a33f63943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9926666666666667, 0.9886666666666667, 0.9906666666666667, 0.9826666666666667, 0.9913333333333333]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qa8tnSKOtBR",
        "outputId": "5b7963ab-0533-495f-9dce-2d3611eef9e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9986522911051213, 0.997979797979798, 0.9979825151311366, 0.9993265993265993, 0.9986541049798116]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nQJTR8bO8Te",
        "outputId": "d49c5ee4-e8cb-49bf-a07a-1bbed1c465a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9993275050437123, 0.9993275050437123, 0.9979852249832102, 0.9986541049798116, 0.9986541049798116]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYpju7XFO-eb",
        "outputId": "791e5862-c320-4bce-93e3-660109127667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.86651411136537, 0.8750946252838759, 0.8733889310083396, 0.8682406702208683, 0.8682406702208683]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdWUam8pO-Qi",
        "outputId": "9bc3a3ff-43e1-419b-ff82-b061f0662f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9986541049798116, 0.9986541049798116, 0.9986559139784946, 0.9986541049798116, 0.9986541049798116]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MviuJ5hO9Mz",
        "outputId": "0cdf0f86-b726-4fd4-be1b-326f9d93294d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9845117845117846, 0.9818181818181818, 0.9790964261631827, 0.9838274932614555, 0.9824561403508772]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7hJIexLO9Ac",
        "outputId": "efaf6ec7-511f-4331-eba9-2754267a27b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9926124916051041, 0.98859825620389, 0.9906040268456376, 0.9825503355704698, 0.9912457912457913]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h12xx6WGPaFZ",
        "outputId": "beb0cd0f-5de3-4210-88b6-cc673593f080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for ANN model: 0.9985333333333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for ANN model:\", average_accuracy_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNI2UNuYPZ5u",
        "outputId": "dddc4fbb-2eee-4ffd-b4a9-7a6d26c73391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for ANN model: 0.9985190617044933\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for ANN model:\", average_f1_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xELmPi5PZtl",
        "outputId": "3d5e6ec2-699b-4e4f-999f-52254c58c43a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for LR model: 0.9987999999999999\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for LR model:\", average_accuracy_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqTAV-tSPZf6",
        "outputId": "39a53968-ea04-49ad-f300-ec16277676ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for LR model: 0.9987896890060515\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for LR model:\", average_f1_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0-FqY-pPZOd",
        "outputId": "6e408611-95b7-4956-c232-900153acdc5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for KNN model: 0.8862666666666668\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for KNN model:\", average_accuracy_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhgYLW1aPZA0",
        "outputId": "fb75c568-4355-4e4a-b16e-3e48b6fdb2b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for KNN model: 0.8702958016198643\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for KNN model:\", average_f1_KNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYOxneGnPY0u",
        "outputId": "67795ba5-166e-490d-ad58-0a82dd6e7474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for SVM model: 0.9986666666666666\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for SVM model:\", average_accuracy_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOO-XfuzPYoy",
        "outputId": "266de577-e746-438b-f620-00cc7f1f3a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for SVM model: 0.9986544667795482\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for SVM model:\", average_f1_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wroUycBPYdy",
        "outputId": "a0f78431-ed61-417a-8684-8cb32ee98a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for RF model: 0.9825333333333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for RF model:\", average_accuracy_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdEuwrBqPYRn",
        "outputId": "c6f7eae3-d10d-4a96-cdab-ff2d2db2ab54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for RF model: 0.9823420052210963\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for RF model:\", average_f1_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eAgArJOPYGK",
        "outputId": "be5f156b-efc9-4060-abd4-56efb9828df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for XGB model: 0.9892\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for XGB model:\", average_accuracy_XGB)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVhIhHUIPX3w",
        "outputId": "4394fe8b-7777-42a7-ef5d-811ea3f1f56d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for XGB model: 0.9891221802941785\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for XGB model:\", average_f1_XGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WunDi9c5wC9f"
      },
      "source": [
        "###**DenseNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R62kMyL0yw_s"
      },
      "source": [
        "Import all libraries required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fSodUS7wK4r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from keras.callbacks import EarlyStopping\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MXb209GwwM6",
        "outputId": "1e2c725b-5b8d-4319-d9cb-2d569156d7bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7000 images belonging to 2 classes.\n",
            "Found 3000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"colon_image_sets\"\n",
        "SIZE_X = SIZE_Y = 224\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.3)\n",
        "\n",
        "train_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X,SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='training',\n",
        "                                       seed = 42)\n",
        "\n",
        "validate_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X, SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='validation',\n",
        "                                       seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKAxf28zw1x3"
      },
      "outputs": [],
      "source": [
        "def get_features(base_model, train, validate):\n",
        "    X_train = base_model.predict(train)\n",
        "    y_train = train.classes\n",
        "\n",
        "    X_val = base_model.predict(validate)\n",
        "    y_val = validate.classes\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5, shuffle = True)\n",
        "    print('Shape of X_train----->', str(X_train.shape))\n",
        "    print('Shape of X_val----->', str(X_val.shape))\n",
        "    print('Shape of X_test----->', str(X_test.shape))\n",
        "    return (X_train, X_val, X_test, y_train, y_val, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wyk-jmyw5A5"
      },
      "outputs": [],
      "source": [
        "def get_models():\n",
        "    ANN = Sequential()\n",
        "    ANN.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
        "    ANN.add(BatchNormalization())\n",
        "    ANN.add(Dropout(0.2))\n",
        "    ANN.add(Dense(64, activation='relu'))\n",
        "    ANN.add(Dense(32, activation='relu'))\n",
        "    ANN.add(Dense(16, activation='relu'))\n",
        "    ANN.add(Dense(8, activation='relu'))\n",
        "    ANN.add(Dense(len(train_it.class_indices), activation='softmax'))\n",
        "    ANN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    LR = LogisticRegression()\n",
        "\n",
        "    KNN = KNeighborsClassifier(n_neighbors=50)\n",
        "\n",
        "    SVM = SVC(kernel = 'linear')\n",
        "\n",
        "    RF = RandomForestClassifier(n_estimators = 50)\n",
        "\n",
        "    XGB = XGBClassifier(n_estimators = 50, use_label_encoder=False)\n",
        "\n",
        "    return (ANN, LR, KNN, SVM, RF, XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vtAD7N8xLO8"
      },
      "outputs": [],
      "source": [
        "def reshape_data(X_train, X_val, X_test):\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_val = X_val.reshape(X_val.shape[0], -1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    print(\"Shape after reshaping------->\")\n",
        "    print(\"X train------->\", str(X_train.shape))\n",
        "    print(\"X val-------->\", str(X_val.shape))\n",
        "    print(\"X test-------->\", str(X_test.shape))\n",
        "\n",
        "    return (X_train, X_val, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGYSMTK4xNUv"
      },
      "outputs": [],
      "source": [
        "def fit_ANN(model, X_train, y_train, X_val, y_test):\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_test), epochs=10, verbose=1, callbacks=[es])\n",
        "    return model\n",
        "\n",
        "def fit_model(model, X_train, y_train):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wx3M06XxXTU",
        "outputId": "fa906d68-bd15-446b-d77b-8597bad604c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d_2 (ZeroPadding2  (None, 230, 230, 3)  0          ['input_10[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d_2[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_3 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_3[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
            " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,037,504\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(SIZE_X, SIZE_Y, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp1FkmRpxfGN",
        "outputId": "4f624509-eacf-41a9-a17e-a3532d4d7772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train-----> (7000, 7, 7, 1024)\n",
            "Shape of X_val-----> (1500, 7, 7, 1024)\n",
            "Shape of X_test-----> (1500, 7, 7, 1024)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = get_features(model, train_it, validate_it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppNtctinxylK",
        "outputId": "75e25b59-cd15-419c-b69e-9824b58d6d38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after reshaping------->\n",
            "X train-------> (7000, 50176)\n",
            "X val--------> (1500, 50176)\n",
            "X test--------> (1500, 50176)\n",
            "Epoch 1/10\n",
            "175/175 [==============================] - 25s 139ms/step - loss: 0.2244 - accuracy: 0.9091 - val_loss: 0.2017 - val_accuracy: 0.9100\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 24s 140ms/step - loss: 0.0994 - accuracy: 0.9634 - val_loss: 0.1867 - val_accuracy: 0.9286\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 24s 138ms/step - loss: 0.0716 - accuracy: 0.9700 - val_loss: 0.2107 - val_accuracy: 0.9350\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 24s 136ms/step - loss: 0.0551 - accuracy: 0.9796 - val_loss: 0.0743 - val_accuracy: 0.9750\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 23s 129ms/step - loss: 0.0418 - accuracy: 0.9846 - val_loss: 0.1855 - val_accuracy: 0.9321\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 24s 138ms/step - loss: 0.0348 - accuracy: 0.9873 - val_loss: 0.1426 - val_accuracy: 0.9557\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 26s 147ms/step - loss: 0.0248 - accuracy: 0.9907 - val_loss: 0.0756 - val_accuracy: 0.9793\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 23s 131ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.0928 - val_accuracy: 0.9757\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 23s 130ms/step - loss: 0.0266 - accuracy: 0.9898 - val_loss: 0.1119 - val_accuracy: 0.9664\n",
            "Epoch 9: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 17s 99ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.0269 - val_accuracy: 0.9936\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 18s 100ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 0.0213 - val_accuracy: 0.9921\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 18s 102ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.0596 - val_accuracy: 0.9829\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 18s 103ms/step - loss: 0.0295 - accuracy: 0.9898 - val_loss: 0.1553 - val_accuracy: 0.9357\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 17s 99ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.0356 - val_accuracy: 0.9879\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 17s 99ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.0454 - val_accuracy: 0.9886\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 18s 105ms/step - loss: 0.0206 - accuracy: 0.9923 - val_loss: 0.7685 - val_accuracy: 0.7707\n",
            "Epoch 7: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 18s 105ms/step - loss: 0.0337 - accuracy: 0.9879 - val_loss: 0.1439 - val_accuracy: 0.9736\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 18s 103ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 1.7856 - val_accuracy: 0.6607\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 18s 103ms/step - loss: 0.0218 - accuracy: 0.9916 - val_loss: 0.4475 - val_accuracy: 0.9643\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 18s 103ms/step - loss: 0.0240 - accuracy: 0.9912 - val_loss: 0.5791 - val_accuracy: 0.9421\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 18s 102ms/step - loss: 0.0239 - accuracy: 0.9907 - val_loss: 0.2215 - val_accuracy: 0.9921\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 17s 99ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.3147 - val_accuracy: 0.9971\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 19s 108ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.0144 - val_accuracy: 0.9936\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 19s 106ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 9.9907e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 19s 107ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.0702 - val_accuracy: 0.9714\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 18s 102ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0022 - val_accuracy: 0.9993\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 17s 100ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.0124 - val_accuracy: 0.9950\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 17s 99ms/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 0.0152 - val_accuracy: 0.9943\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 18s 100ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.0077 - val_accuracy: 0.9986\n",
            "Epoch 7: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 19s 106ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 19s 109ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.0157 - val_accuracy: 0.9950\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 18s 103ms/step - loss: 0.0133 - accuracy: 0.9946 - val_loss: 0.0039 - val_accuracy: 0.9986\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 18s 105ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0073 - val_accuracy: 0.9964\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 18s 103ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 17s 98ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0073 - val_accuracy: 0.9979\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test = reshape_data(X_train, X_val, X_test)\n",
        "ANN, LR, KNN, SVM, RF, XGB = get_models()\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define number of splits for K-Fold cross-validation\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "# Initialize lists to store performance metrics for each fold\n",
        "accuracy_scores_ANN = []\n",
        "f1_scores_ANN = []\n",
        "accuracy_scores_LR = []\n",
        "f1_scores_LR = []\n",
        "accuracy_scores_KNN = []\n",
        "f1_scores_KNN = []\n",
        "accuracy_scores_SVM = []\n",
        "f1_scores_SVM = []\n",
        "accuracy_scores_RF = []\n",
        "f1_scores_RF = []\n",
        "accuracy_scores_XGB = []\n",
        "f1_scores_XGB = []\n",
        "# Perform K-Fold cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Train ANN model\n",
        "    ANN_fold = fit_ANN(ANN, X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "    # Evaluate ANN model\n",
        "    accuracy_ANN = accuracy_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    f1_ANN = f1_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    accuracy_scores_ANN.append(accuracy_ANN)\n",
        "    f1_scores_ANN.append(f1_ANN)\n",
        "\n",
        "    # Train LR model\n",
        "    LR_fold = fit_model(LR, X_train_fold, y_train_fold)\n",
        "    # Evaluate LR model\n",
        "    accuracy_LR = accuracy_score(y_test, LR_fold.predict(X_test))\n",
        "    accuracy_scores_LR.append(accuracy_LR)\n",
        "    f1_LR=f1_score(y_test, LR_fold.predict(X_test))\n",
        "    f1_scores_LR.append(f1_LR)\n",
        "\n",
        "    # Train KNN model\n",
        "    KNN_fold = fit_model(KNN, X_train_fold, y_train_fold)\n",
        "    # Evaluate KNN model\n",
        "    accuracy_KNN = accuracy_score(y_test, KNN_fold.predict(X_test))\n",
        "    accuracy_scores_KNN.append(accuracy_KNN)\n",
        "    f1_KNN=f1_score(y_test, KNN_fold.predict(X_test))\n",
        "    f1_scores_KNN.append(f1_KNN)\n",
        "\n",
        "    # Train SVM model\n",
        "    SVM_fold = fit_model(SVM, X_train_fold, y_train_fold)\n",
        "    # Evaluate SVM model\n",
        "    accuracy_SVM = accuracy_score(y_test, SVM_fold.predict(X_test))\n",
        "    accuracy_scores_SVM.append(accuracy_SVM)\n",
        "    f1_SVM=f1_score(y_test, SVM_fold.predict(X_test))\n",
        "    f1_scores_SVM.append(f1_SVM)\n",
        "\n",
        "    # Train RF model\n",
        "    RF_fold = fit_model(RF, X_train_fold, y_train_fold)\n",
        "    # Evaluate RF model\n",
        "    accuracy_RF = accuracy_score(y_test, RF_fold.predict(X_test))\n",
        "    accuracy_scores_RF.append(accuracy_RF)\n",
        "    f1_RF=f1_score(y_test, RF_fold.predict(X_test))\n",
        "    f1_scores_RF.append(f1_RF)\n",
        "\n",
        "    # Train XGB model\n",
        "    XGB_fold = fit_model(XGB, X_train_fold, y_train_fold)\n",
        "    # Evaluate XGB model\n",
        "    accuracy_XGB = accuracy_score(y_test, XGB_fold.predict(X_test))\n",
        "    accuracy_scores_XGB.append(accuracy_XGB)\n",
        "    f1_XGB=f1_score(y_test, XGB_fold.predict(X_test))\n",
        "    f1_scores_XGB.append(f1_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAjLbMWdOeXi"
      },
      "outputs": [],
      "source": [
        "average_accuracy_ANN = np.mean(accuracy_scores_ANN)\n",
        "average_f1_ANN = np.mean(f1_scores_ANN)\n",
        "average_accuracy_LR = np.mean(accuracy_scores_LR)\n",
        "average_f1_LR = np.mean(f1_scores_LR)\n",
        "average_accuracy_KNN = np.mean(accuracy_scores_KNN)\n",
        "average_f1_KNN = np.mean(f1_scores_KNN)\n",
        "average_accuracy_SVM = np.mean(accuracy_scores_SVM)\n",
        "average_f1_SVM = np.mean(f1_scores_SVM)\n",
        "average_accuracy_RF = np.mean(accuracy_scores_RF)\n",
        "average_f1_RF = np.mean(f1_scores_RF)\n",
        "average_accuracy_XGB = np.mean(accuracy_scores_XGB)\n",
        "average_f1_XGB = np.mean(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8Cb8oxjQd_L",
        "outputId": "10a5b64b-5a0b-4c99-8e89-1bd8199cd919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.968, 0.7706666666666667, 0.984, 0.982, 0.9806666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRTqqZO3Qd0R",
        "outputId": "dbf133e7-eb78-4ad3-c414-9d263dca2c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9813333333333333, 0.9673333333333334, 0.9773333333333334, 0.9793333333333333, 0.9713333333333334]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSs4ImauQdp3",
        "outputId": "fcaf92fe-7d9c-41f1-d9e3-4b0b1f99de9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8846666666666667, 0.8853333333333333, 0.888, 0.882, 0.8873333333333333]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzzW6wNVQdgg",
        "outputId": "2a314a70-4c7b-4c6a-d693-4989ec4a2060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.982, 0.9766666666666667, 0.9793333333333333, 0.9813333333333333, 0.9726666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iT0bFUYUQdWW",
        "outputId": "4fa34477-839f-4d8f-a697-df6e61d6bf84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9466666666666667, 0.9473333333333334, 0.9406666666666667, 0.9393333333333334, 0.9433333333333334]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByKRKpIGQdL6",
        "outputId": "9505001f-190d-464c-c534-d34d5fff387f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9693333333333334, 0.9633333333333334, 0.964, 0.9653333333333334, 0.9626666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqN-UmM4QdBx",
        "outputId": "a3c3c356-b940-4b5d-a64c-e482480e02f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9691912708600771, 0.7054794520547945, 0.9840425531914894, 0.9823644676681906, 0.9811074918566774]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtFvlRpKQc4H",
        "outputId": "6b20370b-a914-41bd-a859-edbc830d1c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9815303430079156, 0.9676140118968936, 0.9775725593667546, 0.9794293297942933, 0.9715796430931923]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpbSMuFNQct-",
        "outputId": "12cc16c9-6778-44f2-fb2e-4aa1cb5a138f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8950879320800484, 0.8955042527339003, 0.8974358974358975, 0.8925318761384335, 0.8973891924711597]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mmw_SPM-Qcil",
        "outputId": "0acce2ae-e753-408f-e939-8d5ddcf9ac7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.982178217821782, 0.9768976897689768, 0.9795649307844428, 0.9815059445178336, 0.9729015201586253]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxRqPBuXQcYI",
        "outputId": "e4df83e4-1d55-45a4-c734-a336b3639502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9480519480519479, 0.9485342019543972, 0.9423948220064724, 0.9412524209167203, 0.9451258876694643]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTFnpfTfQcNb",
        "outputId": "1f8ef74b-6edb-4429-8669-2601cb7f5390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9701298701298702, 0.9642160052049447, 0.9647979139504562, 0.9661016949152542, 0.9636363636363636]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdpwyRaiQcDT",
        "outputId": "c0976af0-976b-4a5c-ac81-f0adf85d3cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for ANN model: 0.9370666666666667\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for ANN model:\", average_accuracy_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHy8FgPhQb4V",
        "outputId": "be786cec-12ad-4e5f-fde4-70a39a548548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for ANN model: 0.9244370471262459\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for ANN model:\", average_f1_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlRGxmJCQbts",
        "outputId": "bbaeaa9e-909a-42d2-fa1f-a1265e19cea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for LR model: 0.9753333333333334\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for LR model:\", average_accuracy_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQsdIg_nQbjB",
        "outputId": "3d0f9159-e600-486e-c9ae-875d0e5b6a0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for LR model: 0.9755451774318098\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for LR model:\", average_f1_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilemuW9FQbYF",
        "outputId": "10689462-5062-4b26-f8c0-d3575203c1b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for KNN model: 0.8854666666666666\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for KNN model:\", average_accuracy_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIJlsueSQbMn",
        "outputId": "100dff06-db23-48f9-8529-671c8a094787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for KNN model: 0.8955898301718879\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for KNN model:\", average_f1_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEchryRfQbB7",
        "outputId": "157f6b99-fc35-4a6c-a754-8a888db50b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for SVM model: 0.9784\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for SVM model:\", average_accuracy_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKgu9lHDQa3B",
        "outputId": "4829001d-beb7-4124-e7fd-600305d90f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for SVM model: 0.978609660610332\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for SVM model:\", average_f1_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVllm7CjQarC",
        "outputId": "abc6062a-477c-4bd0-eb2f-058bef348ffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for RF model: 0.9434666666666667\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for RF model:\", average_accuracy_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkMVZjhaQahJ",
        "outputId": "0e03a8df-6c6c-44a5-9d58-f758957c5d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for RF model: 0.9450718561198004\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for RF model:\", average_f1_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHLtajd1QaWo",
        "outputId": "502cc38d-770c-4c02-f6bd-482bf5ba05cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for XGB model: 0.9649333333333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for XGB model:\", average_accuracy_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qf4d1JB2QaOI",
        "outputId": "42f6e3af-7759-47ad-f44a-c306e8443649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for XGB model: 0.9657763695673778\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for XGB model:\", average_f1_XGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLwIzlYawTr7"
      },
      "source": [
        "###**EfficientNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cILhUGTAyzEP"
      },
      "source": [
        "Import all libraries required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvnlvOhqwYsJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from keras.callbacks import EarlyStopping\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LrPfmZdwz5m",
        "outputId": "6649c2b2-d883-4d7f-a741-2b0c66f46652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7000 images belonging to 2 classes.\n",
            "Found 3000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"colon_image_sets\"\n",
        "SIZE_X = SIZE_Y = 224\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.3)\n",
        "\n",
        "train_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X,SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='training',\n",
        "                                       seed = 42)\n",
        "\n",
        "validate_it = datagen.flow_from_directory(data_dir,\n",
        "                                       class_mode = \"categorical\",\n",
        "                                       target_size = (SIZE_X, SIZE_Y),\n",
        "                                       color_mode=\"rgb\",\n",
        "                                       batch_size = 12,\n",
        "                                       shuffle = False,\n",
        "                                       subset='validation',\n",
        "                                       seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4mlBPg5w0lt"
      },
      "outputs": [],
      "source": [
        "def get_features(base_model, train, validate):\n",
        "    X_train = base_model.predict(train)\n",
        "    y_train = train.classes\n",
        "\n",
        "    X_val = base_model.predict(validate)\n",
        "    y_val = validate.classes\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5, shuffle = True)\n",
        "    print('Shape of X_train----->', str(X_train.shape))\n",
        "    print('Shape of X_val----->', str(X_val.shape))\n",
        "    print('Shape of X_test----->', str(X_test.shape))\n",
        "    return (X_train, X_val, X_test, y_train, y_val, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYoatlpKw70l"
      },
      "outputs": [],
      "source": [
        "def get_models():\n",
        "    ANN = Sequential()\n",
        "    ANN.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
        "    ANN.add(BatchNormalization())\n",
        "    ANN.add(Dropout(0.2))\n",
        "    ANN.add(Dense(64, activation='relu'))\n",
        "    ANN.add(Dense(32, activation='relu'))\n",
        "    ANN.add(Dense(16, activation='relu'))\n",
        "    ANN.add(Dense(8, activation='relu'))\n",
        "    ANN.add(Dense(len(train_it.class_indices), activation='softmax'))\n",
        "    ANN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    LR = LogisticRegression()\n",
        "\n",
        "    KNN = KNeighborsClassifier(n_neighbors=50)\n",
        "\n",
        "    SVM = SVC(kernel = 'linear')\n",
        "\n",
        "    RF = RandomForestClassifier(n_estimators = 50)\n",
        "\n",
        "    XGB = XGBClassifier(n_estimators = 50, use_label_encoder=False)\n",
        "\n",
        "    return (ANN, LR, KNN, SVM, RF, XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCsVDv7xxIfH"
      },
      "outputs": [],
      "source": [
        "def reshape_data(X_train, X_val, X_test):\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_val = X_val.reshape(X_val.shape[0], -1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    print(\"Shape after reshaping------->\")\n",
        "    print(\"X train------->\", str(X_train.shape))\n",
        "    print(\"X val-------->\", str(X_val.shape))\n",
        "    print(\"X test-------->\", str(X_test.shape))\n",
        "\n",
        "    return (X_train, X_val, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dBEuWxDxQSQ"
      },
      "outputs": [],
      "source": [
        "def fit_ANN(model, X_train, y_train, X_val, y_test):\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_test), epochs=10, verbose=1, callbacks=[es])\n",
        "    return model\n",
        "\n",
        "def fit_model(model, X_train, y_train):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbok-5hBxTwR",
        "outputId": "2f5b2325-7e04-4730-d674-dc93c7970ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " rescaling_1 (Rescaling)        (None, 224, 224, 3)  0           ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " normalization_1 (Normalization  (None, 224, 224, 3)  7          ['rescaling_1[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding2D)  (None, 225, 225, 3)  0           ['normalization_1[0][0]']        \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['stem_conv_pad[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, 112, 112, 32  0           ['stem_bn[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['stem_activation[0][0]']        \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1a_dwconv[0][0]']         \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_activation (Activation  (None, 112, 112, 32  0          ['block1a_bn[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1a_activation[0][0]',     \n",
            "                                )                                 'block1a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, 112, 112, 16  512         ['block1a_se_excite[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, 112, 112, 16  64         ['block1a_project_conv[0][0]']   \n",
            " lization)                      )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, 112, 112, 96  1536        ['block1a_project_bn[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, 112, 112, 96  384        ['block2a_expand_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, 112, 112, 96  0          ['block2a_expand_bn[0][0]']      \n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPaddin  (None, 113, 113, 96  0          ['block2a_expand_activation[0][0]\n",
            " g2D)                           )                                ']                               \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 96)  864         ['block2a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormalization  (None, 56, 56, 96)  384         ['block2a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2a_activation (Activation  (None, 56, 56, 96)  0           ['block2a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multiply)   (None, 56, 56, 96)   0           ['block2a_activation[0][0]',     \n",
            "                                                                  'block2a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, 56, 56, 24)   2304        ['block2a_se_excite[0][0]']      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block2b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, 56, 56, 144)  0          ['block2b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 144)  1296       ['block2b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormalization  (None, 56, 56, 144)  576        ['block2b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2b_activation (Activation  (None, 56, 56, 144)  0          ['block2b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multiply)   (None, 56, 56, 144)  0           ['block2b_activation[0][0]',     \n",
            "                                                                  'block2b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, 56, 56, 24)   3456        ['block2b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, 56, 56, 24)   0           ['block2b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, 56, 56, 24)   0           ['block2b_drop[0][0]',           \n",
            "                                                                  'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block3a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, 56, 56, 144)  0          ['block3a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPaddin  (None, 59, 59, 144)  0          ['block3a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormalization  (None, 28, 28, 144)  576        ['block3a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_activation (Activation  (None, 28, 28, 144)  0          ['block3a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multiply)   (None, 28, 28, 144)  0           ['block3a_activation[0][0]',     \n",
            "                                                                  'block3a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, 28, 28, 40)   5760        ['block3a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block3b_expand_conv[0][0]']    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, 28, 28, 240)  0          ['block3b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 240)  6000       ['block3b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormalization  (None, 28, 28, 240)  960        ['block3b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_activation (Activation  (None, 28, 28, 240)  0          ['block3b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multiply)   (None, 28, 28, 240)  0           ['block3b_activation[0][0]',     \n",
            "                                                                  'block3b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, 28, 28, 40)   9600        ['block3b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, 28, 28, 40)   0           ['block3b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, 28, 28, 40)   0           ['block3b_drop[0][0]',           \n",
            "                                                                  'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block4a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, 28, 28, 240)  0          ['block4a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPaddin  (None, 29, 29, 240)  0          ['block4a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, 14, 14, 240)  960        ['block4a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, 14, 14, 240)  0          ['block4a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, 14, 14, 240)  0           ['block4a_activation[0][0]',     \n",
            "                                                                  'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, 14, 14, 80)   19200       ['block4a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, 14, 14, 480)  0          ['block4b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, 14, 14, 480)  0          ['block4b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4b_activation[0][0]',     \n",
            "                                                                  'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, 14, 14, 80)   0           ['block4b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, 14, 14, 80)   0           ['block4b_drop[0][0]',           \n",
            "                                                                  'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, 14, 14, 480)  0          ['block4c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, 14, 14, 480)  0          ['block4c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4c_activation[0][0]',     \n",
            "                                                                  'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, 14, 14, 80)   0           ['block4c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, 14, 14, 80)   0           ['block4c_drop[0][0]',           \n",
            "                                                                  'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, 14, 14, 480)  0          ['block5a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  12000      ['block5a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block5a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, 14, 14, 480)  0          ['block5a_bn[0][0]']             \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block5a_activation[0][0]',     \n",
            "                                                                  'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, 14, 14, 112)  53760       ['block5a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, 14, 14, 672)  0          ['block5b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, 14, 14, 672)  0          ['block5b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5b_activation[0][0]',     \n",
            "                                                                  'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, 14, 14, 112)  0           ['block5b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, 14, 14, 112)  0           ['block5b_drop[0][0]',           \n",
            "                                                                  'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, 14, 14, 672)  0          ['block5c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, 14, 14, 672)  0          ['block5c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5c_activation[0][0]',     \n",
            "                                                                  'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, 14, 14, 112)  0           ['block5c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, 14, 14, 112)  0           ['block5c_drop[0][0]',           \n",
            "                                                                  'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, 14, 14, 672)  0          ['block6a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPaddin  (None, 17, 17, 672)  0          ['block6a_expand_activation[0][0]\n",
            " g2D)                                                            ']                               \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, 7, 7, 672)   2688        ['block6a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, 7, 7, 672)   0           ['block6a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, 7, 7, 672)    0           ['block6a_activation[0][0]',     \n",
            "                                                                  'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, 7, 7, 192)    129024      ['block6a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6b_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, 7, 7, 1152)  0           ['block6b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6b_activation[0][0]',     \n",
            "                                                                  'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6b_project_conv[0][0]']   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, 7, 7, 192)    0           ['block6b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, 7, 7, 192)    0           ['block6b_drop[0][0]',           \n",
            "                                                                  'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6c_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, 7, 7, 1152)  0           ['block6c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6c_activation[0][0]',     \n",
            "                                                                  'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, 7, 7, 192)    0           ['block6c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, 7, 7, 192)    0           ['block6c_drop[0][0]',           \n",
            "                                                                  'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6d_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, 7, 7, 1152)  0           ['block6d_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6d_activation[0][0]',     \n",
            "                                                                  'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, 7, 7, 192)    0           ['block6d_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, 7, 7, 192)    0           ['block6d_drop[0][0]',           \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                  'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block7a_expand_activation (Act  (None, 7, 7, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  10368       ['block7a_expand_activation[0][0]\n",
            " D)                                                              ']                               \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block7a_activation (Activation  (None, 7, 7, 1152)  0           ['block7a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block7a_activation[0][0]',     \n",
            "                                                                  'block7a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv2D)  (None, 7, 7, 320)    368640      ['block7a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchNorma  (None, 7, 7, 320)   1280        ['block7a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, 7, 7, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, 7, 7, 1280)   5120        ['top_conv[0][0]']               \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, 7, 7, 1280)   0           ['top_bn[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,571\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,571\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(SIZE_X, SIZE_Y, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djzUKsaFxmZS",
        "outputId": "537887e6-dadc-4a12-9821-70561358f749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train-----> (7000, 7, 7, 1280)\n",
            "Shape of X_val-----> (1500, 7, 7, 1280)\n",
            "Shape of X_test-----> (1500, 7, 7, 1280)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = get_features(model, train_it, validate_it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_gj6WQcx1bC",
        "outputId": "528742de-acc6-4d75-b0e4-aa9a3826cbcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after reshaping------->\n",
            "X train-------> (7000, 62720)\n",
            "X val--------> (1500, 62720)\n",
            "X test--------> (1500, 62720)\n",
            "Epoch 1/10\n",
            "175/175 [==============================] - 12s 63ms/step - loss: 0.0784 - accuracy: 0.9723 - val_loss: 0.0080 - val_accuracy: 0.9979\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 11s 63ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0314 - val_accuracy: 0.9857\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 11s 63ms/step - loss: 0.0140 - accuracy: 0.9948 - val_loss: 0.0100 - val_accuracy: 0.9964\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0072 - val_accuracy: 0.9979\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0054 - val_accuracy: 0.9979\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.0097 - val_accuracy: 0.9971\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0053 - val_accuracy: 0.9986\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0095 - val_accuracy: 0.9957\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.0287 - val_accuracy: 0.9914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 12s 66ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 5.1377e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 13s 71ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 1.7710e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 12s 67ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 8.6887e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 12s 66ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0037 - val_accuracy: 0.9986\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 12s 66ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0124 - val_accuracy: 0.9964\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 12s 70ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 12s 69ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0166 - val_accuracy: 0.9943\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 12s 67ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 1.9600e-04 - val_accuracy: 1.0000\n",
            "Epoch 8: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 11s 62ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 11s 62ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0091 - val_accuracy: 0.9979\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 3.6051e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 11s 62ms/step - loss: 5.2539e-04 - accuracy: 0.9998 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 11s 63ms/step - loss: 5.0388e-04 - accuracy: 0.9996 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 11s 62ms/step - loss: 8.7645e-04 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 11s 63ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9979\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 11s 63ms/step - loss: 3.6609e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9986\n",
            "Epoch 8: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.0073 - val_accuracy: 0.9986\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0326 - val_accuracy: 0.9993\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 11s 63ms/step - loss: 9.7679e-04 - accuracy: 0.9996 - val_loss: 0.0486 - val_accuracy: 0.9993\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0452 - val_accuracy: 0.9993\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0259 - val_accuracy: 0.9986\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0324 - val_accuracy: 0.9993\n",
            "Epoch 6: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 11s 64ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 9.7504e-04 - accuracy: 0.9996 - val_loss: 4.7914e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.9516e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 11s 62ms/step - loss: 4.1690e-04 - accuracy: 0.9998 - val_loss: 7.7938e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 11s 62ms/step - loss: 1.2157e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 2.3419e-04 - accuracy: 0.9998 - val_loss: 2.8921e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 11s 62ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 11s 63ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0064 - val_accuracy: 0.9993\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 11s 61ms/step - loss: 1.7528e-04 - accuracy: 1.0000 - val_loss: 2.2020e-04 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test = reshape_data(X_train, X_val, X_test)\n",
        "ANN, LR, KNN, SVM, RF, XGB = get_models()\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define number of splits for K-Fold cross-validation\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "# Initialize lists to store performance metrics for each fold\n",
        "accuracy_scores_ANN = []\n",
        "f1_scores_ANN = []\n",
        "accuracy_scores_LR = []\n",
        "f1_scores_LR = []\n",
        "accuracy_scores_KNN = []\n",
        "f1_scores_KNN = []\n",
        "accuracy_scores_SVM = []\n",
        "f1_scores_SVM = []\n",
        "accuracy_scores_RF = []\n",
        "f1_scores_RF = []\n",
        "accuracy_scores_XGB = []\n",
        "f1_scores_XGB = []\n",
        "# Perform K-Fold cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Train ANN model\n",
        "    ANN_fold = fit_ANN(ANN, X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "    # Evaluate ANN model\n",
        "    accuracy_ANN = accuracy_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    f1_ANN = f1_score(y_test, np.argmax(ANN_fold.predict(X_test), axis=1))\n",
        "    accuracy_scores_ANN.append(accuracy_ANN)\n",
        "    f1_scores_ANN.append(f1_ANN)\n",
        "\n",
        "    # Train LR model\n",
        "    LR_fold = fit_model(LR, X_train_fold, y_train_fold)\n",
        "    # Evaluate LR model\n",
        "    accuracy_LR = accuracy_score(y_test, LR_fold.predict(X_test))\n",
        "    accuracy_scores_LR.append(accuracy_LR)\n",
        "    f1_LR=f1_score(y_test, LR_fold.predict(X_test))\n",
        "    f1_scores_LR.append(f1_LR)\n",
        "\n",
        "    # Train KNN model\n",
        "    KNN_fold = fit_model(KNN, X_train_fold, y_train_fold)\n",
        "    # Evaluate KNN model\n",
        "    accuracy_KNN = accuracy_score(y_test, KNN_fold.predict(X_test))\n",
        "    accuracy_scores_KNN.append(accuracy_KNN)\n",
        "    f1_KNN=f1_score(y_test, KNN_fold.predict(X_test))\n",
        "    f1_scores_KNN.append(f1_KNN)\n",
        "\n",
        "    # Train SVM model\n",
        "    SVM_fold = fit_model(SVM, X_train_fold, y_train_fold)\n",
        "    # Evaluate SVM model\n",
        "    accuracy_SVM = accuracy_score(y_test, SVM_fold.predict(X_test))\n",
        "    accuracy_scores_SVM.append(accuracy_SVM)\n",
        "    f1_SVM=f1_score(y_test, SVM_fold.predict(X_test))\n",
        "    f1_scores_SVM.append(f1_SVM)\n",
        "\n",
        "    # Train RF model\n",
        "    RF_fold = fit_model(RF, X_train_fold, y_train_fold)\n",
        "    # Evaluate RF model\n",
        "    accuracy_RF = accuracy_score(y_test, RF_fold.predict(X_test))\n",
        "    accuracy_scores_RF.append(accuracy_RF)\n",
        "    f1_RF=f1_score(y_test, RF_fold.predict(X_test))\n",
        "    f1_scores_RF.append(f1_RF)\n",
        "\n",
        "    # Train XGB model\n",
        "    XGB_fold = fit_model(XGB, X_train_fold, y_train_fold)\n",
        "    # Evaluate XGB model\n",
        "    accuracy_XGB = accuracy_score(y_test, XGB_fold.predict(X_test))\n",
        "    accuracy_scores_XGB.append(accuracy_XGB)\n",
        "    f1_XGB=f1_score(y_test, XGB_fold.predict(X_test))\n",
        "    f1_scores_XGB.append(f1_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25opAKaTOf66"
      },
      "outputs": [],
      "source": [
        "average_accuracy_ANN = np.mean(accuracy_scores_ANN)\n",
        "average_f1_ANN = np.mean(f1_scores_ANN)\n",
        "average_accuracy_LR = np.mean(accuracy_scores_LR)\n",
        "average_f1_LR = np.mean(f1_scores_LR)\n",
        "average_accuracy_KNN = np.mean(accuracy_scores_KNN)\n",
        "average_f1_KNN = np.mean(f1_scores_KNN)\n",
        "average_accuracy_SVM = np.mean(accuracy_scores_SVM)\n",
        "average_f1_SVM = np.mean(f1_scores_SVM)\n",
        "average_accuracy_RF = np.mean(accuracy_scores_RF)\n",
        "average_f1_RF = np.mean(f1_scores_RF)\n",
        "average_accuracy_XGB = np.mean(accuracy_scores_XGB)\n",
        "average_f1_XGB = np.mean(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vPQsW32RHgH",
        "outputId": "e2a93166-d3f5-4a8f-b613-c3650a87a3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9946666666666667, 0.998, 0.998, 0.9993333333333333, 1.0]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QWCbPYYRHT4",
        "outputId": "a44f8e27-93d9-44db-8dec-01c0b44d9e44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9993333333333333, 0.9986666666666667, 1.0, 0.9993333333333333, 0.998]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2i50rjwRHIt",
        "outputId": "a48a5516-fbbd-43ac-9609-7b89298fde36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9626666666666667, 0.9593333333333334, 0.9613333333333334, 0.9613333333333334, 0.9653333333333334]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pMReaRERG9g",
        "outputId": "2df5f832-c1e9-4db9-ad0c-0076d80826f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9993333333333333, 1.0, 1.0, 0.9993333333333333, 0.9993333333333333]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6KstdQWRGxR",
        "outputId": "9396d46c-0bbc-4744-bf0a-5f0285d45642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.968, 0.9713333333333334, 0.9706666666666667, 0.974, 0.974]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu1vPuxwRGn6",
        "outputId": "f45539b9-b253-4ae9-cc45-ed768d60f902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9846666666666667, 0.9853333333333333, 0.9873333333333333, 0.9833333333333333, 0.9826666666666667]\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms_gy2EoRGdf",
        "outputId": "ce7e6fda-2691-4a07-97b1-b47da5daac34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9946452476572958, 0.9979825151311366, 0.9979825151311366, 0.9993265993265993, 1.0]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYMynuzkRGQu",
        "outputId": "3d1c0bd2-85f6-40c1-d1fa-837652c6b1d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9993275050437123, 0.9986522911051213, 1.0, 0.9993265993265993, 0.997979797979798]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hok95bEaRGEw",
        "outputId": "4d73e11e-908a-44c6-d6aa-78140983b72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9614855570839064, 0.9582477754962354, 0.9600550964187327, 0.9600550964187327, 0.9641873278236914]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfypm5XsRF5z",
        "outputId": "1aa9b86c-a5ed-4dc4-9b84-6aa0d30f2a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9993275050437123, 1.0, 1.0, 0.9993265993265993, 0.9993275050437123]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFYOW2oORFuV",
        "outputId": "ad4b99df-e706-4ee0-9632-702b0df1d532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.967741935483871, 0.9709263015551046, 0.9702702702702702, 0.9736664415935178, 0.9737373737373738]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55WM9h51RFkN",
        "outputId": "4bc47bdc-a4af-4cd5-c10a-d88794494659"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.9845117845117846, 0.9851951547779273, 0.9872053872053872, 0.9831195138419987, 0.98252688172043]\n"
          ]
        }
      ],
      "source": [
        "print(f1_scores_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9ICnZQyRFbF",
        "outputId": "0fdeb01c-87e9-4510-f77a-afcdbfb17493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for ANN model: 0.998\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for ANN model:\", average_accuracy_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yapu3usLRFQ9",
        "outputId": "4ac1a3b9-a533-4568-947a-a552ca8560f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for ANN model: 0.9979873754492337\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for ANN model:\", average_f1_ANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oN6OebB7RFGh",
        "outputId": "d6adef10-7b33-43c2-85ab-85072f35e03b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for LR model: 0.9990666666666668\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for LR model:\", average_accuracy_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAU4XmLeRE6i",
        "outputId": "5d4012d5-009f-4454-e02c-adae6dedfc48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for LR model: 0.9990572386910461\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for LR model:\", average_f1_LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7B0oK_9REvW",
        "outputId": "7e69b4b3-e2cd-45d3-f0fb-92adb3e926f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for KNN model: 0.9620000000000001\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for KNN model:\", average_accuracy_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXnR-vULREio",
        "outputId": "898c49e5-c28c-45ae-8a6c-41f778e7f474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for KNN model: 0.9608061706482596\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for KNN model:\", average_f1_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8juniIFREYs",
        "outputId": "312d55c1-4b83-4e46-dd73-a97af0a222f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for SVM model: 0.9996\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for SVM model:\", average_accuracy_SVM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQDdbR9bREOZ",
        "outputId": "93289ac1-948f-44bd-9d73-847e631ad8f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for SVM model: 0.9995963218828049\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for SVM model:\", average_f1_SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHDZKFKiRED4",
        "outputId": "bdae8a52-8c53-48b7-e6b7-e0fb7ab048fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for RF model: 0.9716000000000001\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for RF model:\", average_accuracy_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u_17iNjRD4L",
        "outputId": "00f46227-76d0-4d9f-8716-561a8b64705c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for RF model: 0.9712684645280275\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for RF model:\", average_f1_RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA3dIeeKRDuy",
        "outputId": "59aa293c-a6b5-44c5-8c9a-4ff3606f804a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy for XGB model: 0.9846666666666666\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Accuracy for XGB model:\", average_accuracy_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to-_9VelRDk5",
        "outputId": "20567089-e1d7-48f0-bbdb-e6e6c74694a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 for XGB model: 0.9845117444115055\n"
          ]
        }
      ],
      "source": [
        "print(\"Average F1 for XGB model:\", average_f1_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCL6D-60wtcQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrEhUh0jwtcQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "r0RzVVG_GFIp",
        "sEncClbaL_OU",
        "frHO81G3oGI4",
        "LG1a6rx3KesO",
        "oMhJO0pTuDE0"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}